{
  "hash": "a2953d7126143e9a3edac18e049537aa",
  "result": {
    "markdown": "---\ntitle: \"Similarity and Equivalence in Two-Mode Networks\"\nexecute: \n  eval: true\n  echo: true\n  output: true\n  warning: false\n  message: false\nformat: \n   html:\n      code-line-numbers: true\n---\n\n   \n## Normalized Vertex Similarity Metrics\n\nNote that the [one-mode projections](tm-duality.qmd) can be considered unnormalized similarity matrices [just like in the case of regular networks](similarity.qmd). That means that if we have the degrees of nodes in each mode, we can transform this matrix into any of the **normalized vertex similarity** metrics we discussed before, including Jaccard, Cosine, Dice, LHN, and so on. \n\nLet's see how this would work in our trusty *Southern Women* dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(igraph)\n   library(networkdata)\n   g <- southern_women\n   A <- as_biadjacency_matrix(g)\n```\n:::\n\n\nRepackaging our vertex similarity function for the two-mode case, we have:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   vertex.sim <- function(x) {\n      A <- as.matrix(as_biadjacency_matrix(x))\n      M <- nrow(A) #number of persons\n      N <- ncol(A) #number of groups\n      p.d <- rowSums(A) #person degrees\n      g.d <- colSums(A) #group degrees\n      P <- A %*% t(A) #person projection\n      G <- t(A) %*% A #group projection\n      J.p <- diag(1, M, M)\n      J.g <- diag(1, N, N)\n      C.p <- diag(1, M, M)\n      C.g <- diag(1, N, N)\n      D.p <- diag(1, M, M)\n      D.g <- diag(1, N, N)\n      L.p <- diag(1, M, M)\n      L.g <- diag(1, N, N)\n      for (i in 1:M) {\n         for (j in 1:M) {\n            if (i < j) {\n               J.p[i,j] <- P[i,j]/(P[i,j] + p.d[i] + p.d[j])\n               J.p[j,i] <- P[i,j]/(P[i,j] + p.d[i] + p.d[j])\n               C.p[i,j] <- P[i,j]/(sqrt(p.d[i] * p.d[j]))\n               C.p[j,i] <- P[i,j]/(sqrt(p.d[i] * p.d[j]))\n               D.p[i,j] <- (2*P[i,j])/(2*P[i,j] + p.d[i] + p.d[j])\n               D.p[j,i] <- (2*P[i,j])/(2*P[i,j] + p.d[i] + p.d[j])\n               L.p[i,j] <- P[i,j]/(p.d[i] * p.d[j])\n               L.p[j,i] <- P[i,j]/(p.d[i] * p.d[j])\n               }\n            }\n         }\n      for (i in 1:N) {\n         for (j in 1:N) {\n            if (i < j) {\n               J.g[i,j] <- G[i,j]/(G[i,j] + g.d[i] + g.d[j])\n               J.g[j,i] <- G[i,j]/(G[i,j] + g.d[i] + g.d[j])\n               C.g[i,j] <- G[i,j]/(sqrt(g.d[i] * g.d[j]))\n               C.g[j,i] <- G[i,j]/(sqrt(g.d[i] * g.d[j]))\n               D.g[i,j] <- (2*G[i,j])/(2*G[i,j] + g.d[i] + g.d[j])\n               D.g[j,i] <- (2*G[i,j])/(2*G[i,j] + g.d[i] + g.d[j])\n               L.g[i,j] <- G[i,j]/(g.d[i] * g.d[j])\n               L.g[j,i] <- G[i,j]/(g.d[i] * g.d[j])\n               }\n            }\n         }\n      return(list(J.p = J.p, C.p = C.p, D.p = D.p, L.p = L.p,\n                  J.g = J.g, C.g = C.g, D.g = D.g, L.g = L.g))\n      }\n```\n:::\n\n\nUsing this function to compute the Jaccard similarity between people yields:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   J.p <- vertex.sim(g)$J.p\n   rownames(J.p) <- rownames(A)\n   colnames(J.p) <- rownames(A)\n   round(J.p, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          EVELYN LAURA THERESA BRENDA CHARLOTTE FRANCES ELEANOR PEARL RUTH\nEVELYN      1.00  0.29    0.30   0.29      0.20    0.25    0.20  0.21 0.20\nLAURA       0.29  1.00    0.29   0.30      0.21    0.27    0.27  0.17 0.21\nTHERESA     0.30  0.29    1.00   0.29      0.25    0.25    0.25  0.21 0.25\nBRENDA      0.29  0.30    0.29   1.00      0.27    0.27    0.27  0.17 0.21\nCHARLOTTE   0.20  0.21    0.25   0.27      1.00    0.20    0.20  0.00 0.20\nFRANCES     0.25  0.27    0.25   0.27      0.20    1.00    0.27  0.22 0.20\nELEANOR     0.20  0.27    0.25   0.27      0.20    0.27    1.00  0.22 0.27\nPEARL       0.21  0.17    0.21   0.17      0.00    0.22    0.22  1.00 0.22\nRUTH        0.20  0.21    0.25   0.21      0.20    0.20    0.27  0.22 1.00\nVERNE       0.14  0.15    0.20   0.15      0.11    0.11    0.20  0.22 0.27\nMYRNA       0.14  0.08    0.14   0.08      0.00    0.11    0.11  0.22 0.20\nKATHERINE   0.12  0.07    0.12   0.07      0.00    0.09    0.09  0.18 0.17\nSYLVIA      0.12  0.12    0.17   0.12      0.08    0.08    0.15  0.17 0.21\nNORA        0.11  0.12    0.16   0.12      0.08    0.08    0.14  0.15 0.14\nHELEN       0.07  0.14    0.13   0.14      0.10    0.10    0.18  0.11 0.18\nDOROTHY     0.17  0.10    0.17   0.10      0.00    0.14    0.14  0.29 0.25\nOLIVIA      0.09  0.00    0.09   0.00      0.00    0.00    0.00  0.17 0.14\nFLORA       0.09  0.00    0.09   0.00      0.00    0.00    0.00  0.17 0.14\n          VERNE MYRNA KATHERINE SYLVIA NORA HELEN DOROTHY OLIVIA FLORA\nEVELYN     0.14  0.14      0.12   0.12 0.11  0.07    0.17   0.09  0.09\nLAURA      0.15  0.08      0.07   0.12 0.12  0.14    0.10   0.00  0.00\nTHERESA    0.20  0.14      0.12   0.17 0.16  0.13    0.17   0.09  0.09\nBRENDA     0.15  0.08      0.07   0.12 0.12  0.14    0.10   0.00  0.00\nCHARLOTTE  0.11  0.00      0.00   0.08 0.08  0.10    0.00   0.00  0.00\nFRANCES    0.11  0.11      0.09   0.08 0.08  0.10    0.14   0.00  0.00\nELEANOR    0.20  0.11      0.09   0.15 0.14  0.18    0.14   0.00  0.00\nPEARL      0.22  0.22      0.18   0.17 0.15  0.11    0.29   0.17  0.17\nRUTH       0.27  0.20      0.17   0.21 0.14  0.18    0.25   0.14  0.14\nVERNE      1.00  0.27      0.23   0.27 0.20  0.25    0.25   0.14  0.14\nMYRNA      0.27  1.00      0.29   0.27 0.20  0.25    0.25   0.14  0.14\nKATHERINE  0.23  0.29      1.00   0.32 0.26  0.21    0.20   0.11  0.11\nSYLVIA     0.27  0.27      0.32   1.00 0.29  0.25    0.18   0.10  0.10\nNORA       0.20  0.20      0.26   0.29 1.00  0.24    0.09   0.17  0.17\nHELEN      0.25  0.25      0.21   0.25 0.24  1.00    0.12   0.12  0.12\nDOROTHY    0.25  0.25      0.20   0.18 0.09  0.12    1.00   0.20  0.20\nOLIVIA     0.14  0.14      0.11   0.10 0.17  0.12    0.20   1.00  0.33\nFLORA      0.14  0.14      0.11   0.10 0.17  0.12    0.20   0.33  1.00\n```\n:::\n:::\n\n\n## Structural Equivalence\n\nAnd, of course, once we have a similarity we can cluster nodes based on approximate structural equivalence by transforming proximities to distances:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   D <- as.dist(1- J.p)\n   hc.p <- hclust(D, method = \"ward.D2\")\n   plot(hc.p)\n```\n\n::: {.cell-output-display}\n![](tm-siilarity_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nAnd for events:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   J.g <- vertex.sim(g)$J.g\n   rownames(J.g) <- colnames(A)\n   colnames(J.g) <- colnames(A)\n   D <- as.dist(1- J.g)\n   hc.g <- hclust(D, method = \"ward.D2\")\n   plot(hc.g)\n```\n\n::: {.cell-output-display}\n![](tm-siilarity_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nWe can then derive cluster memberships for people and groups from the `hclust` object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(dendextend)\n   clus.p <- sort(cutree(hc.p, 4)) #selecting four clusters for people\n   clus.p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        1         1         1         1         1         1         1         2 \n     RUTH     VERNE   DOROTHY     MYRNA KATHERINE    SYLVIA      NORA     HELEN \n        2         2         2         3         3         3         3         3 \n   OLIVIA     FLORA \n        4         4 \n```\n:::\n\n```{.r .cell-code}\n   clus.g <- sort(cutree(hc.g, 3)) #selecting three clusters for groups\n   clus.g\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    1     1     1     1     1     1     2     2     2     3     3     3     3 \n  8/3 \n    3 \n```\n:::\n:::\n\n\nAnd finally we can block the original affiliation matrix, as recommended by @everett_borgatti13 [p. 210, table 5]:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(ggcorrplot)\n   p <- ggcorrplot(t(A[names(clus.p), names(clus.g)]), \n                   colors = c(\"white\", \"white\", \"red\")) \n   p <- p + theme(legend.position = \"none\", \n                  axis.text.y = element_text(size = 8),\n                  axis.text.x = element_text(size = 8, angle = 0),\n                  )\n   p <- p + scale_x_discrete(position = \"top\") \n   p <- p + geom_hline(yintercept = 7.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_hline(yintercept = 11.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_hline(yintercept = 16.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_vline(xintercept = 6.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_vline(xintercept = 9.5, linewidth = 2, color = \"blue\")\n   p\n```\n\n::: {.cell-output-display}\n![](tm-siilarity_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nWhich reveals a number of almost complete (one-blocks) and almost null (zero-blocks) in the social structure, with a reduced image matrix that looks like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(kableExtra)\n   IM <- matrix(0, 4, 3)\n   IM[1, ] <- c(0, 1, 0)\n   IM[2, ] <- c(0, 1, 1)\n   IM[3, ] <- c(0, 1, 0)\n   IM[4, ] <- c(1, 1, 0)\n   rownames(IM) <- c(\"P.Block1\", \"P.Block2\", \"P.Block3\", \"P.Block4\")\n   colnames(IM) <- c(\"E.Block1\", \"E.Block2\", \"E.Block3\")\n   kbl(IM, format = \"html\", , align = \"c\") %>% \n      column_spec(1, bold = TRUE) %>% \n      kable_styling(full_width = TRUE,\n                     bootstrap_options = c(\"hover\", \"condensed\", \"responsive\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover table-condensed table-responsive\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\"> E.Block1 </th>\n   <th style=\"text-align:center;\"> E.Block2 </th>\n   <th style=\"text-align:center;\"> E.Block3 </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> P.Block1 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> P.Block2 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> P.Block3 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-weight: bold;\"> P.Block4 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Generalized Vertex Similarity\n\nRecall that vertex similarity works using the principle of *structural equivalence*: Two people are similar if the choose the *same* objects (groups), and two objects (groups) are similar if they are chosen by the *same* people. \n\nWe can, like we did in the one mode case, be after a more general version of similarity, which says that: Two people are similar if they choose *similar* (not necessarily the same) objects, and two objects are similar if they are chosen by *similar* (not necessarily the same) people.\n\nThis leads to the same problem setup that inspired the **SimRank** approach [@jeh_widom02]. \n\nA (longish) function to compute the SimRank similarity between nodes in a two mode network goes as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   TM.SimRank <- function(A, C = 0.8, iter = 10) {\n        nr <- nrow(A)\n        nc <- ncol(A)\n        dr <- rowSums(A)\n        dc <- colSums(A)\n        Sr <- diag(1, nr, nr) #baseline similarity: every node maximally similar to themselves\n        Sc <- diag(1, nc, nc) #baseline similarity: every node maximally similar to themselves\n        rn <- rownames(A)\n        cn <- colnames(A)\n        rownames(Sr) <- rn\n        colnames(Sr) <- rn\n        rownames(Sc) <- cn\n        colnames(Sc) <- cn\n        m <- 1\n        while(m < iter) {\n             Sr.pre <- Sr\n             Sc.pre <- Sc\n             for(i in 1:nr) {\n                  for(j in 1:nr) {\n                       if (i != j) {\n                            a <- names(which(A[i, ] == 1)) #objects chosen by i\n                            b <- names(which(A[j, ] == 1)) #objects chosen by j\n                            Scij <- 0\n                            for (k in a) {\n                                 for (l in b) {\n                                      Scij <- Scij + Sc[k, l] #i's similarity to j\n                                 }\n                            }\n                            Sr[i, j] <- C/(dr[i] * dr[j]) * Scij\n                       }\n                  }\n             }\n             for(i in 1:nc) {\n                  for(j in 1:nc) {\n                       if (i != j) {\n                            a <- names(which(A[, i] == 1)) #people who chose object i\n                            b <- names(which(A[, j] == 1)) #people who chose object j\n                            Srij <- 0\n                            for (k in a) {\n                                 for (l in b) {\n                                      Srij <- Srij + Sr[k, l] #i's similarity to j\n                                 }\n                            }\n                            Sc[i, j] <- C/(dc[i] * dc[j]) * Srij\n                       }\n                  }\n             }\n             m <- m + 1\n        }\n        return(list(Sr = Sr, Sc = Sc))\n   }\n```\n:::\n\n\nThis function takes the biadjacency matrix $\\mathbf{A}$ as input and returns two generalized relational similarity matrices: One for the people (row objects) and the other one for the groups (column objects).\n\nHere's how that would work in the SW data. First we compute the SimRank scores:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   sim.res <- TM.SimRank(A)\n```\n:::\n\n\nThen we peek inside the people similarity matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(sim.res$Sr[1:10, 1:10], 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          EVELYN LAURA THERESA BRENDA CHARLOTTE FRANCES ELEANOR PEARL  RUTH\nEVELYN     1.000 0.267   0.262  0.266     0.259   0.275   0.248 0.255 0.237\nLAURA      0.267 1.000   0.262  0.277     0.270   0.287   0.280 0.237 0.247\nTHERESA    0.262 0.262   1.000  0.262     0.273   0.270   0.264 0.254 0.256\nBRENDA     0.266 0.277   0.262  1.000     0.290   0.287   0.279 0.235 0.246\nCHARLOTTE  0.259 0.270   0.273  0.290     1.000   0.276   0.269 0.175 0.256\nFRANCES    0.275 0.287   0.270  0.287     0.276   1.000   0.305 0.280 0.256\nELEANOR    0.248 0.280   0.264  0.279     0.269   0.305   1.000 0.279 0.294\nPEARL      0.255 0.237   0.254  0.235     0.175   0.280   0.279 1.000 0.279\nRUTH       0.237 0.247   0.256  0.246     0.256   0.256   0.294 0.279 1.000\nVERNE      0.201 0.207   0.222  0.206     0.198   0.202   0.246 0.276 0.288\n          VERNE\nEVELYN    0.201\nLAURA     0.207\nTHERESA   0.222\nBRENDA    0.206\nCHARLOTTE 0.198\nFRANCES   0.202\nELEANOR   0.246\nPEARL     0.276\nRUTH      0.288\nVERNE     1.000\n```\n:::\n:::\n\n\nAnd the group similarity matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(sim.res$Sc[1:10, 1:10], 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10\n6/27 1.000 0.343 0.314 0.312 0.287 0.277 0.224 0.226 0.178 0.137\n3/2  0.343 1.000 0.312 0.311 0.285 0.276 0.224 0.228 0.200 0.141\n4/12 0.314 0.312 1.000 0.314 0.288 0.265 0.226 0.220 0.179 0.138\n9/26 0.312 0.311 0.314 1.000 0.287 0.256 0.230 0.214 0.186 0.137\n2/25 0.287 0.285 0.288 0.287 1.000 0.260 0.235 0.226 0.187 0.146\n5/19 0.277 0.276 0.265 0.256 0.260 1.000 0.224 0.226 0.200 0.171\n3/15 0.224 0.224 0.226 0.230 0.235 0.224 1.000 0.221 0.204 0.209\n9/16 0.226 0.228 0.220 0.214 0.226 0.226 0.221 1.000 0.221 0.214\n4/8  0.178 0.200 0.179 0.186 0.187 0.200 0.204 0.221 1.000 0.234\n6/10 0.137 0.141 0.138 0.137 0.146 0.171 0.209 0.214 0.234 1.000\n```\n:::\n:::\n\n\nLike before we can use these results to define two sets of distances:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   D.p <- as.dist(1 - sim.res$Sr)\n   D.g <- as.dist(1 - sim.res$Sc)\n```\n:::\n\n\nSubject to hierarchical clustering:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   hc.p <- hclust(D.p, method = \"ward.D2\")\n   hc.g <- hclust(D.g, method = \"ward.D2\")\n```\n:::\n\n\nAnd plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   plot(hc.p)\n```\n\n::: {.cell-output-display}\n![](tm-siilarity_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n   plot(hc.g)\n```\n\n::: {.cell-output-display}\n![](tm-siilarity_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n:::\n\n\nGet cluster memberships for people and groups from the `hclust` object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   clus.p <- sort(cutree(hc.p, 4)) #selecting four clusters for people\n   clus.p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        1         1         1         1         1         1         1         2 \n     RUTH     VERNE   DOROTHY     MYRNA KATHERINE    SYLVIA      NORA     HELEN \n        2         2         2         3         3         3         3         3 \n   OLIVIA     FLORA \n        4         4 \n```\n:::\n\n```{.r .cell-code}\n   clus.g <- sort(cutree(hc.g, 3)) #selecting three clusters for groups\n   clus.g\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  2/23  6/10   4/7 11/21 \n    1     1     1     1     1     1     2     2     2     2     3     3     3 \n  8/3 \n    3 \n```\n:::\n:::\n\n\nAnd block the biadjacency matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   p <- ggcorrplot(t(A[names(clus.p), names(clus.g)]), \n                   colors = c(\"white\", \"white\", \"red\")) \n   p <- p + theme(legend.position = \"none\", \n                  axis.text.y = element_text(size = 8),\n                  axis.text.x = element_text(size = 8, angle = 0),\n                  )\n   p <- p + scale_x_discrete(position = \"top\") \n   p <- p + geom_hline(yintercept = 7.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_hline(yintercept = 11.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_hline(yintercept = 16.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_vline(xintercept = 6.5, linewidth = 2, color = \"blue\")\n   p <- p + geom_vline(xintercept = 10.5, linewidth = 2, color = \"blue\")\n   p\n```\n\n::: {.cell-output-display}\n![](tm-siilarity_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nNote that this block solution is similar (pun intended) but not *exactly* the same as the one based on structural equivalence we obtained earlier, although it would lead to the same reduced image matrix for the blocks.",
    "supporting": [
      "tm-siilarity_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}