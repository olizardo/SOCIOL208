---
title: "Statistical Models of Networks"
execute: 
  eval: true
  echo: true
  output: true
  warning: false
  message: false
format: 
   html:
      code-line-numbers: true
---

So far we have treated the observed ties in a given network as given, along with any metrics computed from those ties (e.g., attribute correlations, centralities, etc.). The idea of uncertainty around an estimate, foundational to traditional statistics, has so far not been applicable.

Another approach, and one that brings in concerns about inference, statistical significance, and so forth, is to think of the observed network data as a *realization* of some underlying random or probabilistic process. 

## Random Networks

There are many ways to go about this, but here we will cover two important ones. First we can treat the *whole network* as a realization of some random process. That leads to models of **random networks** and **graph ensembles** [@orsini_etal15] that are useful for testing single hypotheses (e.g., are the levels of homophily that I am observing in this network more or less than we would expect by chance?). 

Second, there are models that treat each *link* in the network as a realization of some random process [@pattison_robins12]. Because a network is just a set of links these models are also treating the network as random, but allow us to test more fine-grained multivariate hypothesis by conditioning on characteristics of the ties and the nodes that are involved in each link. This is the family of **exponential random graph models** for networks usually abbreviated as ERGMs and pronounced "ergums." 

In this handout we will discuss the first of these strategies. 

## Graph Ensembles

A **graph ensemble** is just a set of graphs that share some graph level property (like the ones we studied in the very first handout). For instance, they might have the same number of nodes, or the same number of edges, or both, but are different in terms of which particular nodes connect to which. Note that if an ensemble of graphs has the same number of nodes and edges, they will also be identical with regard to any property that is a function of these two things, like the density. 

Usually, what we would want is a graph ensemble that matches the properties that we observe in a graph that corresponds to the network of interest. The idea is to create an ensemble of graphs that are similar to our original data. We can then use the ensemble to test whether some quantity we observe in our data is larger or smaller than we would expect by chance. Here "chance" is simply the probability of observing that value in the ensemble of graphs we created. 

As @orsini_etal15 note, a simple way to create an ensemble is just by using an **edge swapping algorithm** on the original graph. Each edge swapping algorithm works by *preserving* some property of the original graph across each realization, so that all the graphs in the ensemble share that property.

In the simplest case, we create an ensemble that preserves the number of nodes and edges of the original graph (and everything that is a function of these, like density and average degree) and randomizes everything else in each graph in the ensemble relative to the observed graph. 

Let's see how this would work. First we load up a network, in this case Krackardt's high tech managers data:

```{r}
   library(networkdata)
   library(igraph)
   g <- ht_friends
   g <- as_undirected(g, mode = "collapse")
```

This is the undirected version of the friendship nominations network. Let's review some graph properties:

```{r}
   vcount(g)
   ecount(g)
   edge_density(g)
   mean(degree(g))
```

We can see that we have $|V| = 21$, $|E|=79$, $d=0.38$, and $\bar{k}=7.5$.

Here's a function that takes the original graph as input and produces another graph with everything scrambled up, but that retains the same statistics we just listed:

```{r}
   swap1 <- function(x) {
      s <- 0 
      m <- ecount(x)*2
      while(s <= m) {
         c <- complementer(g)
         a <- as.vector(ends(x, sample(E(x), 1))) 
         b <- as.vector(ends(c, sample(E(c), 1))) 
         x <- x - edge(a[1], a[2]) #delete random edge
         x <- x + edge(b[1], b[2]) #add edge between unconnected nodes
         x <- x + edge(b[2], b[1]) #add edge between unconnected nodes
         s <- s + 1
         }
      return(x)
   }
```

This function samples a random edge from the graph in line 6, then, in line 7, it samples a random edge from the *complement* of the graph (obtained in line 5), which are disconnected vertices in the original graph. It then deletes the randomly sampled edge in line 8 and adds it to the disconnected vertices in lines 9-10, repeating this process `m` times (set to twice the number of edges). 
Let's see it in action:

```{r}
   set.seed (123)
   g.swap <- swap1(g)
   vcount(g.swap)
   ecount(g.swap)
   edge_density(g.swap)
   mean(degree(g.swap))
```

Which preserved the original number of nodes, number, edges, density and average degree. Here's a side-by-side comparison:

```{r}
#| fig-height: 12
#| fig-width: 12
#| fig-subcap:
#|   - "Original Friendship Network."
#|   - "One Density Preserving Swap."
#| layout-ncol: 2
#| echo: false
   set.seed(123)
   plot(g, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25,
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(g.swap, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
```

Note that while we preferred *some* structural features of the original network, the swapped graph has a very different structure!

Here are two other graphs that also have the same average degree and density as the original:

```{r}
   set.seed (456)
   g.swap2 <- swap1(g)
   set.seed (789)
   g.swap3 <- swap1(g)
```

```{r}
#| fig-height: 12
#| fig-width: 12
#| fig-subcap:
#|   - "Another Density Preserving Swap."
#|   - "Yet Another Density Preserving Swap."
#| layout-ncol: 2
#| echo: false
   set.seed(123)
   plot(g.swap2, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25,
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(g.swap3, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
```

One of the reasons why these graphs looks so different from the original is that while these graphs all have the same **average degree** as the original, the specific degrees of each node are *not* preserved. This is clear if you compare node 14 in the original graph (which is well-connected) to node 14 in the graph to the right of the original, where they only have two friends. 

We will learn how to create graph ensembles that preserve specific node degrees in a bit. But first, let's see what we can do with graph ensembles.

## Null Hypothesis Testing

Remember that one thing we wanted to do is **null hypothesis testing**; that is, we want to see if something computed in the original graph is more or less than we would expect by chance, given a suitable "null model", which in our case is a network where the density---and thus expected degree---is preserved but people connect at random (sometimes called an **Erdos-Renyi** model). 

So let's compute something:

```{r}
   assortativity(g, V(g)$level)
```

This is Newman's **assortativity coefficient** (a.k.a. the modularity) for the nominal category of "Level" telling us that ties are more likely to form between managers of the same department in the company. Is this a "statistically significant" level of assortativity? 

Well compared to what? Compared to what we observe in an ensemble of graphs with the same number of nodes, edges, and density!

So let's create an ensemble of 100 graphs:

```{r}
   G <- list() 
   set.seed(12345)
   for (i in 1:100) {
      G[[i]] <- swap1(g)
   }
```

And now we compute our assortativity coefficient in each one of them:

```{r}
   assort <- sapply(G, assortativity, values = V(g)$level)
   round(assort, 2)
```

Note that the modularity is actually negative in most of these graphs, suggesting that when people form ties at random they are unlikely to magically end up being assortative by department. 

So let's see how our observed value stacks up in the grand scheme:

```{r}
   library(ggplot2)
   p <- ggplot(data = data.frame(round(assort, 2)), aes(x = assort))
   p <- p + geom_histogram(binwidth = 0.0125, stat = "bin", fill = "darkblue")
   p <- p + geom_vline(xintercept = assortativity(g, V(g)$level), 
                       color = "red", linetype = 1, linewidth = 1.5)
   p <- p + geom_vline(xintercept = 0, linetype = 1, 
                       color = "purple", linewidth = 1.5)
   p <- p + theme_minimal() + labs(x = "Q by Level", y = "Freq.")
   p <- p + theme(axis.text = element_text(size = 12))
   p <- p + annotate("text", x=-0.03, y=9.4, label= "Zero Point", color = "purple")
   p <- p + annotate("text", x=0.06, y=9.4, label= "Obs. Value", color = "red")
   p
```

So we can see that only a few of the networks in the ensemble have $Q$ values higher than the observed one, indicating that what we observed is unlikely to have occurred by chance. 

How unlikely? We can just compute the value that corresponds to the 95th percentile of the assortativity distribution from the ensemble and then see if what observe is above that value. Let's try $p < 0.01$

```{r}
   quantile(assort, probs = 0.99)
   assortativity(g, V(g)$level) > quantile(assort, probs = 0.99)
```

We find that our observed value of assortativity by dept is not significant at this level, as the corresponding value in the ensemble distribution is higher. 


Of course we can also try a less stringent standard for statistical significance, like $p < 0.05$:

```{r}
   quantile(assort, probs = 0.95)
   assortativity(g, V(g)$level) > quantile(assort, probs = 0.95)
```

Which, in this case, is "statistically significant"! This is because the observed value is larger than the corresponding value at the 95th percentile slot of the graph ensemble distribution. 

If we wanted to find the actual "p-value" corresponding to our observed value, we would just type the following, which uses the native `R` function `ecdf`:

```{r}
   1 - ecdf(assort)(assortativity(g, V(g)$level))
```

Which yields $p = 0.02$ for our observed value of assortativity by department.

## Preserving Degrees

Recall that our swapping function above preserves the *expected* (average) degree but not the degree of any particular node. This means that the neither the **degree sequence** nor the **degree distribution** of the original network is preserved. 

This is clear in the following plots:

```{r}
   library(dplyr)
   library(tidyr)
   deg.dat <- data.frame(Original = degree(g), Swap1 = degree(g.swap), Swap2 = degree(g.swap2), Swap3 = degree(g.swap3)) %>% 
   pivot_longer(1:4, names_to = "graph") %>% 
      mutate(v = sort(rep(1:vcount(g), 4)))
   p <- ggplot(data = deg.dat, aes(x = value, group = graph, fill = graph))
   p <- p + geom_histogram(binwidth = 0.35)
   p <- p + facet_wrap(~ graph, nrow = 4)
   p <- p + theme_minimal()
   p <- p + theme(legend.position = "none",
                  axis.text = element_text(size = 12),
                  strip.text = element_text(size = 14),
                  axis.title = element_text(size = 14)) 
   p <- p + scale_x_continuous(breaks = c(1:18))
   p <- p + labs(x = "", y ="")
   p
```

The top shows the original degree distribution, which is different from the ones in the swapped graphs. 

So it could be that the simple **average degree** (Erdos-Renyi) preserving model is to simple to use as a plausible null model. A better model is one that would preserve the degrees of each node in the ensemble but make every connection random. 

In `igraph` there is a trusty function called `keeping_degseq` which is used along with the more general function `rewire` to scramble the edges in a graph. In this case `keeping_degseq` will randomly rewire the edges in the graph while preserving the degrees of each node.

The basic idea is to sample a pair of edges connecting vertices $a$ and $b$ and $c$ and $d$ respectively, delete them, and create two new edges (if they don't currently exist) between vertices $a$ and $c$ and between $b$ and $d$, repeating this process `m` number of times. 

Let's see how it works:

```{r}
   g.swap <- rewire(g, keeping_degseq(niter = 50))
   degree(g)
   degree(g.swap)
```

Which we can see creates a new graph with exactly the same degree sequence as the original. Here they are side-by-side:

```{r}
#| fig-height: 12
#| fig-width: 12
#| fig-subcap:
#|   - "Original Friendship Network."
#|   - "One Degree Preserving Swap."
#| layout-ncol: 2
#| echo: false
   set.seed(123)
   plot(g, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25,
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(g.swap, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
```

So now we can use our more stringent null model to test our previous hypothesis: Is the observed level of assortativity by level more than we would observe in the same network where everyone keeps their degree centrality but everything is random?

Let's find out.

First, let's wrap the degree-preserving swap into a function:

```{r}
   swap2 <- function(x, m = 50) {
      rewire(x, keeping_degseq(niter = m))
   }
```

Then let's create our graph ensemble this time using 500 graphs:

```{r}
   G2 <- list() 
   set.seed(12345)
   for (i in 1:500) {
      G2[[i]] <- swap2(g)
   }
```

And see where our observed value falls in the distribution:

```{r}
   assort <- sapply(G2, assortativity, values = V(g)$level)
   library(ggplot2)
   p <- ggplot(data = data.frame(round(assort, 2)), aes(x = assort))
   p <- p + geom_histogram(binwidth = 0.015, stat = "bin", fill = "darkblue")
   p <- p + geom_vline(xintercept = assortativity(g, V(g)$level), 
                       color = "red", linetype = 1, linewidth = 1.5)
   p <- p + geom_vline(xintercept = 0, linetype = 1, 
                       color = "purple", linewidth = 1.5)
   p <- p + theme_minimal() + labs(x = "Q by Department", y = "Freq.")
   p <- p + theme(axis.text = element_text(size = 12))
   p <- p + annotate("text", x=-0.03, y=170, label= "Zero Point", color = "purple")
   p <- p + annotate("text", x=0.08, y=170, label= "Obs. Value", color = "red")
   p
```

Note that the values are much more constrained this time around, falling within specific ranges. We can test our hypothesis the same way as before:

```{r}
   quantile(assort, probs = 0.95)
   assortativity(g, V(g)$level) > quantile(assort, probs = 0.95)
```

Which tells us that after account for node degree differences, the observed value we observed is not significant using conventional cutoffs. 

Instead, the p-value of the estimate is:

```{r}
   1 - ecdf(assort)(assortativity(g, V(g)$level))
```

Which is close, but not quite at the level of usual standards for statistically significance. 
