{
  "hash": "ecff1168e03412f2323cba8c882f5105",
  "result": {
    "markdown": "---\ntitle: \"Graph Ensembles in Two-Mode Networks\"\nexecute: \n  eval: true\n  echo: true\n  output: true\n  warning: false\n  message: false\nformat: \n   html:\n      code-line-numbers: true\n---\n\n\nAs we saw in the [graph ensemble lesson](swap.qmd), there are many approaches to randomizing the structure of one-mode networks when the aim is to create **graph ensembles** preserving selected properties. These ensembles, in turn, can be used to do **null hypothesis testing** in networks. \n\nNot surprisingly, a similar suite of techniques exist for the two-mode case, but until recently various approaches were scattered (and reduplicated) across a bunch of literatures in social network analysis, ecology, network physics, and  computer science [@neal_etal24]. \n\n## Two-Mode Erdos-Renyi Model\n\nLike with one-mode networks, the simplest null model for two-mode networks is one that preserves the number of nodes and the number of edges. This model, like we saw before, also preserves anything that is a function of these two-quantities. In the two-mode case, this is the bipartite graph's **density** and the average degrees of the nodes in each mode (recall that two-mode networks have two average degrees). This is thus a two-mode version of the **Erdos-Renyi** null model. \n\nLet's load up the *Southern Women* (SW) data and see how it works:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(igraph)\n   library(networkdata)\n   A <- as_biadjacency_matrix(southern_women)\n```\n:::\n\n\nLet's compute some basic network statistics:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   d <- sum(A)/(nrow(A)*ncol(A)) #density\n   ad.p <- mean(rowSums(A)) #average degree of people\n   ad.g <- mean(colSums(A)) #average degree of groups\n   d\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3531746\n```\n:::\n\n```{.r .cell-code}\n   ad.p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.944444\n```\n:::\n\n```{.r .cell-code}\n   ad.g\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.357143\n```\n:::\n:::\n\n\nWe can see that the density of the SW network is $d=$ 0.35, the average degree of people $\\bar{k_p}=$ 4.94 and the average degree of groups $\\bar{k_g}=$ 6.36.  \n\nNow, let's compute something on this network, like the **degree correlation** between people and groups, answering  the question: Do people with lots of memberships tend to join larger groups?\n\nFirst let's create an edge list data frame with the incident nodes' degrees and compute the correlation between the respective degrees:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   v.a <- as.vector(A)\n   rn <- rep(rownames(A), ncol(A))\n   cn <- rep(colnames(A), each = nrow(A))\n   rd <- rep(rowSums(A), ncol(A))\n   cd <- rep(colSums(A), each = nrow(A))\n   d <- data.frame(p = rn,  c = cn, e = v.a, rd =  rd, cd = cd)\n   cor(d[d$e == 1, ]$rd, d[d$e == 1, ]$cd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2783186\n```\n:::\n:::\n\n\nWhich is negative, suggesting degree **anti-correlation** in this network (people with lots of memberships tend to belong to smaller groups). \n\nIs this value statistically significant net of the network density? To find out, we need to create a **two-mode graph ensemble** of networks with the same density, number of persons, and number of groups as SW. \n\nA simple approach goes like this. First, let's create a vectorized version of the adjacency matrix and assign a number from 1:$M$ (where $M = |P| \\times |G|$, the number of cells in the biadjacency matrix) to each value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   v.a <- as.vector(A)\n   M <- nrow(A)*ncol(A)\n   names(v.a) <- 1:M\n   v.a\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  1   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   1   1 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n  1   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   1   1   0 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n  0   0   0   0   0   0   0   0   0   0   0   0   1   1   1   1   1   1   1   0 \n 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 \n  1   0   0   0   0   0   0   0   0   0   1   1   1   1   0   1   1   1   0   0 \n101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 \n  0   0   0   1   0   0   0   0   0   1   1   1   1   0   1   0   1   1   0   0 \n121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 \n  1   1   1   0   0   0   1   1   1   1   0   1   1   1   1   1   1   1   1   0 \n141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 \n  1   1   0   0   1   0   1   0   0   0   0   1   1   1   1   1   1   1   0   1 \n161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 \n  1   1   0   0   0   0   0   0   0   0   0   0   1   1   1   1   1   0   0   0 \n181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 \n  0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0   1   1   0   0 \n201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 \n  0   0   0   0   0   0   0   1   1   1   1   1   1   0   0   0   0   0   0   0 \n221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 \n  0   0   0   0   0   0   0   1   1   1   0   0   0   0   0   0   0   0   0   0 \n241 242 243 244 245 246 247 248 249 250 251 252 \n  0   0   0   0   0   1   1   1   0   0   0   0 \n```\n:::\n:::\n\n\nNow we can just permute the labels of the vector, and  re-order them to generate a new biadjacency matrix `A.perm`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   s <- sample(1:M)\n   v.perm <- v.a\n   names(v.perm) <- s\n   v.perm <- v.perm[names(v.a)] #reordering vector\n   A.perm <- matrix(v.perm, nrow = nrow(A)) #creating permuted biadjacency matrix\n   rownames(A.perm) <- rownames(A)\n   colnames(A.perm) <- colnames(A)\n   A.perm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          6/27 3/2 4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       1   0    1    0    0    1    0    0   0    0    0   0     0   1\nLAURA        0   0    0    0    0    0    0    0   0    0    0   0     0   0\nTHERESA      1   0    1    0    0    0    1    1   0    1    1   0     0   0\nBRENDA       1   0    0    1    0    0    1    0   0    0    0   0     0   0\nCHARLOTTE    0   0    0    0    1    0    0    0   0    0    0   1     1   1\nFRANCES      0   0    1    1    0    1    0    0   0    1    0   0     1   0\nELEANOR      0   1    1    1    0    0    1    1   0    0    0   0     0   1\nPEARL        0   1    1    0    0    0    1    0   0    0    1   1     0   0\nRUTH         0   0    0    0    1    0    1    0   1    0    0   0     0   0\nVERNE        1   0    0    1    0    1    0    1   0    0    0   1     0   1\nMYRNA        0   1    1    1    0    0    0    0   1    1    1   0     0   1\nKATHERINE    1   0    1    0    1    1    0    0   0    1    0   0     0   0\nSYLVIA       0   0    1    0    0    0    1    1   0    1    0   0     1   0\nNORA         0   0    0    0    0    1    0    0   0    0    1   0     1   1\nHELEN        0   0    1    1    0    1    1    0   0    0    0   1     0   1\nDOROTHY      1   0    1    0    0    1    0    0   0    1    1   0     1   1\nOLIVIA       0   0    0    1    0    0    0    0   1    1    1   1     0   1\nFLORA        1   1    0    1    1    0    1    1   0    0    0   0     1   0\n```\n:::\n:::\n\n\nWe can verify that `A.perm` has the same basic network statistics as `A`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   d <- sum(A.perm)/(nrow(A.perm)*ncol(A.perm)) #density\n   ad.p <- mean(rowSums(A.perm)) #average degree of people\n   ad.g <- mean(colSums(A.perm)) #average degree of groups\n   d\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3531746\n```\n:::\n\n```{.r .cell-code}\n   ad.p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.944444\n```\n:::\n\n```{.r .cell-code}\n   ad.g\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.357143\n```\n:::\n:::\n\n\nBut *not* the same degree distributions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   rowSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         7         8         7         4         4         4         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         4         4         6         7         8         5         2 \n   OLIVIA     FLORA \n        2         2 \n```\n:::\n\n```{.r .cell-code}\n   rowSums(A.perm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        4         0         6         3         4         5         6         5 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        3         6         7         5         5         4         6         7 \n   OLIVIA     FLORA \n        6         7 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    3     3     6     4     8     8    10    14    12     5     4     6     3 \n  8/3 \n    3 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A.perm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    7     4    10     8     4     7     8     5     3     7     6     5     6 \n  8/3 \n    9 \n```\n:::\n:::\n\n\n\nWe can now package the two-mode permutation steps into a function called `tm.perm`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   tm.perm <- function(x) {\n      z <- nrow(x)*ncol(x)\n      l <- as.character(1:z)\n      s <- sample(1:z)\n      v <- as.vector(x)\n      names(v) <- s\n      v <- v[l]\n      w <- matrix(v, nrow = nrow(x))\n      rownames(w) <- rownames(x)\n      colnames(w) <- colnames(x)\n      return(w)\n   }\n```\n:::\n\n\nAnd generate an Erdos-Renyi graph ensemble for the SW data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   set.seed(4567)\n   G <- replicate(500, tm.perm(A), simplify = FALSE)\n```\n:::\n\n\nWe then package the steps above into a two-mode degree correlation function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   tm.deg.corr <- function(x) {\n      d <- data.frame(e = as.vector(x), \n                      rd = rep(rowSums(x), ncol(x)), \n                      cd = rep(colSums(x), each = nrow(x)))\n      return(cor(d[d$e == 1, ]$rd, d[d$e == 1, ]$cd))\n   }\n```\n:::\n\n\nAnd compute it across our ensemble:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   corrs <- sapply(G, tm.deg.corr)\n   corrs[1:100] #first hundred entries\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1]  0.0760021893 -0.1348203679 -0.1694265983  0.0718510150 -0.0600115860\n  [6] -0.2374190808  0.0237031449  0.1173741356 -0.0260733311  0.1416253809\n [11]  0.1184189968 -0.0289596593 -0.0730215167  0.0095106371 -0.1964173575\n [16]  0.1596845191 -0.1355133618  0.0180448467 -0.1087077279 -0.1046313791\n [21]  0.0811773307 -0.1700579702 -0.1683615931 -0.0879076569 -0.1708282944\n [26] -0.1234216407 -0.1222169590 -0.1752430252 -0.0771362047  0.0374001159\n [31] -0.3363039453 -0.0215314138 -0.1361914116  0.0236148748  0.0904123313\n [36]  0.0854149823 -0.1092669645 -0.0968902488  0.0655271276  0.0839894527\n [41] -0.1372253130 -0.0250088463 -0.0752489834 -0.0646135286 -0.0050636524\n [46] -0.1434413069  0.0394530627 -0.0294602605  0.0621823678  0.0452125858\n [51]  0.1488401015 -0.1589331412 -0.0150605405 -0.1804322595  0.0553501794\n [56] -0.1313982596 -0.1601437081 -0.0834589259 -0.0318101556 -0.0418927041\n [61] -0.1673209567 -0.0781911355 -0.0237342903 -0.0468442301 -0.1678850228\n [66] -0.1131891529 -0.1385607565 -0.0370619914 -0.1153888854 -0.2140948633\n [71] -0.0023642670 -0.0620337449 -0.0435028327  0.0480923464  0.0542443957\n [76] -0.0877253584 -0.0246771154  0.0005149925  0.1174570125 -0.1311654686\n [81] -0.0993590626 -0.0003062831  0.0357750520 -0.1040233078 -0.2628413829\n [86] -0.1411546883 -0.0616393144  0.0397847088 -0.2262041963 -0.1711172380\n [91] -0.0729372910 -0.0718569434 -0.2789671901 -0.1370995229  0.0519466480\n [96] -0.0714731685 -0.0634881474 -0.0203817674 -0.0830534979  0.0228451012\n```\n:::\n:::\n\n\nSo let's see how our observed value stacks up in the grand scheme:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(ggplot2)\n   p <- ggplot(data = data.frame(round(corrs, 2)), aes(x = corrs))\n   p <- p + geom_histogram(binwidth = 0.015, stat = \"bin\", fill = \"darkblue\")\n   p <- p + geom_vline(xintercept = tm.deg.corr(A), \n                       color = \"red\", linetype = 1, linewidth = 1.5)\n   p <- p + geom_vline(xintercept = 0, linetype = 1, \n                       color = \"purple\", linewidth = 1.5)\n   p <- p + theme_minimal() + labs(x = \"Q by Level\", y = \"Freq.\")\n   p <- p + theme(axis.text = element_text(size = 12))\n   p <- p + annotate(\"text\", x=-0.05, y=47, label= \"Zero Point\", color = \"purple\")\n   p <- p + annotate(\"text\", x=-0.23, y=47, label= \"Obs. Value\", color = \"red\")\n   p\n```\n\n::: {.cell-output-display}\n![](tm-null_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nWhich looks close to the tail end of the negative spectrum. We can compute the value that corresponds to the 99th percentile of the assortativity distribution from the ensemble and then see if what observe is below that value (corresponding to $p < 0.01$). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n   quantile(corrs, probs = 0.99)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      99% \n0.1489135 \n```\n:::\n\n```{.r .cell-code}\n   tm.deg.corr(A) < quantile(corrs, probs = 0.99)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 99% \nTRUE \n```\n:::\n:::\n\n\nWhich is definitely true in this null graph ensemble, suggesting that degree anti-correlation is present in the SW data, net of density. \n\nAs before, if we wanted a more stringent two-tailed we would need to create a vector with the *absolute value* of the two-mode degree correlation: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n   1 - ecdf(abs(corrs))(abs(tm.deg.corr(A)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01\n```\n:::\n:::\n\n\nWhich is stil statistically significant at conventional levels. ",
    "supporting": [
      "tm-null_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}