{
  "hash": "62f06ad565e8d369442a7cdf4c49ca9b",
  "result": {
    "markdown": "---\ntitle: \"Spectral Clustering of Two-Mode Networks\"\nexecute: \n  eval: true\n  echo: true\n  output: true\n  warning: false\n  message: false\nformat: \n   html:\n      code-line-numbers: true\n---\n\n\nWe can use a variant of the [spectral clustering approach](spectral.qmd) to find communities in two-mode networks [@wu_etal22]. This approach combines [Correspondence Analysis (CA)](tm-ca.qmd) and k-means clustering on multiple  dimensions. \n\nSo let's bring back our old friend, the Southern Women data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    library(igraph)\n    library(networkdata)\n    g <- southern_women #southern women data\n    A <- as.matrix(as_biadjacency_matrix(g)) #bi-adjacency matrix\n    A2 <- as.matrix(as_adjacency_matrix(g)) #bipartite adjacency matrix\n```\n:::\n\n\nLet's also compute the bi-adjacency modularity matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   dp <- as.matrix(rowSums(A))\n   dg <- as.matrix(colSums(A))\n   dpdg <- dp %*% t(dg) #person x group degree product matrix\n   B <- A - dpdg/sum(A)\n   round(B, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23\nEVELYN     0.73  0.73  0.46  0.64  0.28  0.28 -0.90 -0.26 -0.08 -0.45 -0.36\nLAURA      0.76  0.76  0.53 -0.31  0.37  0.37  0.21 -0.10 -0.94 -0.39 -0.31\nTHERESA   -0.27  0.73  0.46  0.64  0.28  0.28  0.10 -0.26 -0.08 -0.45 -0.36\nBRENDA     0.76 -0.24  0.53  0.69  0.37  0.37  0.21 -0.10 -0.94 -0.39 -0.31\nCHARLOTTE -0.13 -0.13  0.73  0.82  0.64 -0.36  0.55 -0.63 -0.54 -0.22 -0.18\nFRANCES   -0.13 -0.13  0.73 -0.18  0.64  0.64 -0.45  0.37 -0.54 -0.22 -0.18\nELEANOR   -0.13 -0.13 -0.27 -0.18  0.64  0.64  0.55  0.37 -0.54 -0.22 -0.18\nPEARL     -0.10 -0.10 -0.20 -0.13 -0.27  0.73 -0.34  0.53  0.60 -0.17 -0.13\nRUTH      -0.13 -0.13 -0.27 -0.18  0.64 -0.36  0.55  0.37  0.46 -0.22 -0.18\nVERNE     -0.13 -0.13 -0.27 -0.18 -0.36 -0.36  0.55  0.37  0.46 -0.22 -0.18\nMYRNA     -0.13 -0.13 -0.27 -0.18 -0.36 -0.36 -0.45  0.37  0.46  0.78 -0.18\nKATHERINE -0.20 -0.20 -0.40 -0.27 -0.54 -0.54 -0.67  0.06  0.19  0.66 -0.27\nSYLVIA    -0.24 -0.24 -0.47 -0.31 -0.63 -0.63  0.21 -0.10  0.06  0.61 -0.31\nNORA      -0.27 -0.27 -0.54 -0.36 -0.72  0.28  0.10 -1.26 -0.08  0.55  0.64\nHELEN     -0.17 -0.17 -0.34 -0.22 -0.45 -0.45  0.44  0.21 -0.67  0.72  0.78\nDOROTHY   -0.07 -0.07 -0.13 -0.09 -0.18 -0.18 -0.22  0.69  0.73 -0.11 -0.09\nOLIVIA    -0.07 -0.07 -0.13 -0.09 -0.18 -0.18 -0.22 -0.31  0.73 -0.11  0.91\nFLORA     -0.07 -0.07 -0.13 -0.09 -0.18 -0.18 -0.22 -0.31  0.73 -0.11  0.91\n            4/7 11/21   8/3\nEVELYN    -0.54 -0.27 -0.27\nLAURA     -0.47 -0.24 -0.24\nTHERESA   -0.54 -0.27 -0.27\nBRENDA    -0.47 -0.24 -0.24\nCHARLOTTE -0.27 -0.13 -0.13\nFRANCES   -0.27 -0.13 -0.13\nELEANOR   -0.27 -0.13 -0.13\nPEARL     -0.20 -0.10 -0.10\nRUTH      -0.27 -0.13 -0.13\nVERNE      0.73 -0.13 -0.13\nMYRNA      0.73 -0.13 -0.13\nKATHERINE  0.60  0.80  0.80\nSYLVIA     0.53  0.76  0.76\nNORA       0.46  0.73  0.73\nHELEN      0.66 -0.17 -0.17\nDOROTHY   -0.13 -0.07 -0.07\nOLIVIA    -0.13 -0.07 -0.07\nFLORA     -0.13 -0.07 -0.07\n```\n:::\n:::\n\n\nGreat! Now, from this information we can compute a version of the bipartite modularity matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   n <- nrow(A) + ncol(A)\n   Np <- nrow(A)\n   names <- c(rownames(A), colnames(A))\n   B2 <- matrix(0, n, n) #all zeros matrix of dimensions (p + g) X (p + g)\n   B2[1:Np, (Np + 1):n] <- B #putting B in the top right block\n   B2[(Np + 1):n, 1:Np] <- t(B) #putting B transpose in the lower-left block\n   rownames(B2) <- names\n   colnames(B2) <- names\n```\n:::\n\n\nAnd now let's find the CA scores. This time will use the canned function `CA` from the the package `FactoMineR`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   #install.packages(\"FactoMineR\")\n   library(FactoMineR)\n   CA.res <- CA(A, graph = FALSE, ncp = 10)\n```\n:::\n\n\nWhich computes CA directly on the bi-adjacency matrix (the argument `ncp` asks to keep the first ten dimensions). \n\nWe can now extract the CA scores for persons and groups from the resulting object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   eig.vec.p <- CA.res$row$coord\n   eig.vec.g <- CA.res$col$coord\n   head(eig.vec.p)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Dim 1       Dim 2       Dim 3        Dim 4       Dim 5\nEVELYN    -0.7994396 -0.11278306  0.12856965  0.491615655  0.36993238\nLAURA     -0.8426887  0.03973055  0.11862978  0.286643489  0.10696165\nTHERESA   -0.6538505 -0.08107422  0.03285721  0.066653892  0.11835519\nBRENDA    -0.8552592  0.05084420  0.26039689 -0.082978126  0.05028130\nCHARLOTTE -0.9735517  0.03683948  0.66023345 -0.774105247  0.08510784\nFRANCES   -0.7973597  0.05794469 -0.20558235 -0.001077288 -0.59307835\n                 Dim 6        Dim 7       Dim 8         Dim 9      Dim 10\nEVELYN    -0.007414199 -0.007447136 -0.02256155 -0.0160061655  0.08340311\nLAURA      0.519058804  0.358983310  0.06243870  0.1954326939 -0.10193085\nTHERESA   -0.238792769  0.037114413  0.44547214 -0.1638696977  0.04645662\nBRENDA     0.060849392 -0.093559773 -0.53495958 -0.1262516982  0.02818219\nCHARLOTTE -0.721861078 -0.222554541  0.02152725 -0.0001022383 -0.04432666\nFRANCES    0.178454033 -0.648007177  0.12713961  0.3578859472 -0.29201035\n```\n:::\n\n```{.r .cell-code}\n   head(eig.vec.g)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Dim 1        Dim 2       Dim 3        Dim 4       Dim 5      Dim 6\n6/27 -1.0510521 -0.013102803  0.40045025  0.624502007  0.53693139  0.6062955\n3/2  -0.9662871 -0.090934069  0.22094083  0.758901614  0.60626508  0.2889617\n4/12 -1.0357695 -0.002506996  0.39252639 -0.005949514  0.07005287 -0.1110437\n9/26 -1.0359803 -0.046981456  0.64023822 -0.201296127  0.47641399 -0.7205873\n2/25 -0.8840034  0.002527085  0.00616034 -0.304708001 -0.31330029 -0.1008760\n5/19 -0.5723848 -0.007363883 -0.15907563  0.336653678 -0.55713599  0.3565649\n            Dim 7       Dim 8       Dim 9       Dim 10\n6/27  0.341243814 -0.78585220  0.09303009  0.022211664\n3/2   0.514095893  0.77040262  0.02721689  0.064255000\n4/12 -0.380608237  0.07861703  0.21614264 -0.322353047\n9/26 -0.284177968 -0.10776494 -0.40181489  0.196215569\n2/25  0.009376108  0.04679332  0.31794275  0.121060750\n5/19 -0.215101435  0.05292157 -0.34808611  0.004513752\n```\n:::\n:::\n\n\nGreat! You can verify that these are the same scores we obtained in [two-mode CA lecture](tm-ca.qmd) via a more elaborate route.\n\nNow, we can just create our `U` matrix by stacking the person and group scores using the first three dimensions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   U <- rbind(eig.vec.p, eig.vec.g)[, 1:3]\n   head(U)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Dim 1       Dim 2       Dim 3\nEVELYN    -0.7994396 -0.11278306  0.12856965\nLAURA     -0.8426887  0.03973055  0.11862978\nTHERESA   -0.6538505 -0.08107422  0.03285721\nBRENDA    -0.8552592  0.05084420  0.26039689\nCHARLOTTE -0.9735517  0.03683948  0.66023345\nFRANCES   -0.7973597  0.05794469 -0.20558235\n```\n:::\n\n```{.r .cell-code}\n   tail(U)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Dim 1      Dim 2       Dim 3\n4/8   0.5140165 -0.4896890 -0.47959026\n6/10  1.1173628  0.5729577  0.23464730\n2/23  1.2219952 -2.0539686  0.69618973\n4/7   1.0223902  0.5159415 -0.04625319\n11/21 1.1742556  0.9078702  0.66121084\n8/3   1.1742556  0.9078702  0.66121084\n```\n:::\n:::\n\n\nNice! Now we can just feed `U` to our `k.cuts` function to place persons and groups into cluster assignments beginning with two and ending with ten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   k.cuts <- function(x, max = 9) {\n      clus <- list()\n      for (i in 1:max) {\n         set.seed(456) #setting seed because kmeans uses random starting nodes for cluster centroids\n         k <- i + 1\n         clus[[i]] <- kmeans(x, k)$cluster\n         }\n      return(clus)\n   }\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n   clus <- k.cuts(U)\n```\n:::\n\n\nOf course, we can't use the `mod.check` function [we used before](spectral.qmd) because that relies on the standard method for checking the modularity in one-mode networks and doesn't take into account the structural zeros in the bipartite graph. \n\nSo we need to come up with a custom method to check the modularity for the bipartite case. \n\nFirst, we need a function that takes a cluster assignment vector containing numbers for each cluster $k = \\{1, 2, 3, \\ldots C\\}$ and turns it into a dummy coded cluster assignment matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   make.dummies <- function(x) {\n      vals <- unique(x)\n      U <- matrix(0, length(x), length(vals))\n      for (k in vals) {\n         U[, k] <- as.numeric(x == k)\n      }\n   return(U)\n   }\n```\n:::\n\n\nLet's test it out:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   make.dummies(clus[[3]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      [,1] [,2] [,3] [,4]\n [1,]    0    1    0    0\n [2,]    0    1    0    0\n [3,]    0    1    0    0\n [4,]    0    1    0    0\n [5,]    0    1    0    0\n [6,]    0    1    0    0\n [7,]    0    1    0    0\n [8,]    0    0    0    1\n [9,]    0    0    0    1\n[10,]    0    0    0    1\n[11,]    0    0    0    1\n[12,]    1    0    0    0\n[13,]    1    0    0    0\n[14,]    1    0    0    0\n[15,]    1    0    0    0\n[16,]    0    0    0    1\n[17,]    0    0    1    0\n[18,]    0    0    1    0\n[19,]    0    1    0    0\n[20,]    0    1    0    0\n[21,]    0    1    0    0\n[22,]    0    1    0    0\n[23,]    0    1    0    0\n[24,]    0    1    0    0\n[25,]    0    1    0    0\n[26,]    0    0    0    1\n[27,]    0    0    0    1\n[28,]    1    0    0    0\n[29,]    0    0    1    0\n[30,]    1    0    0    0\n[31,]    1    0    0    0\n[32,]    1    0    0    0\n```\n:::\n:::\n\n\nGreat! Looks like it works. \n\nFinally, we need to write a custom function for bipartite modularity checking across different assignments:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   mod.check2 <- function(x, c, w) {\n      k <- length(c)\n      m <- rep(0, k)\n      for (i in 1:k) {\n         u <- make.dummies(c[[i]])\n         m[i] <- sum(diag(t(u) %*% x %*% u))/sum(w)\n         }\n   names(m) <- 2:(k+1)\n   return(m)\n   }\n```\n:::\n\n\nThe function `mod.check2` needs three inputs: The bipartite modularity matrix, a list with different assignments of the nodes in the bipartite graph to different clusters, and the bipartite adjacency matrix. It returns a vector `m` with the modularities of each of the partitions in the list `c`. \n\nAnd, now, for the big reveal:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(mod.check2(B2, clus, A2), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    2     3     4     5     6     7     8     9    10 \n0.318 0.306 0.338 0.257 0.248 0.224 0.190 0.184 0.155 \n```\n:::\n:::\n\n\nLooks like the spectral clustering results favor a four-community partition although the more parsimonious three and binary community partitions also look pretty good. \n\n@fig-women-1 and @fig-women-2 show a plot of the three and four community solutions according to the CA dimensions (since we already saw the binary partition in the CA handout).\n\nOf course, just like we did with one-mode networks, we can also obtain a spectral clustering directly from the eigenvectors of the bipartite modularity matrix in just a couple of lines:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   clusB <- k.cuts(eigen(B2)$vectors[, 1:2])\n   round(mod.check2(B2, clusB, A2), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    2     3     4     5     6     7     8     9    10 \n0.319 0.334 0.271 0.216 0.179 0.144 0.133 0.101 0.057 \n```\n:::\n:::\n\n\nHere we create the `U` matrix from the first two dimensions of the eigendecomposition of the bipartite modularity matrix. The results suggest that the three community partition is optimal, although the two-community one also does well. The corresponding splits are shown in @fig-women-3 and @fig-women-4. \n\nNote that the main difference between CA and modularity based clustering in two-mode networks is that modularity seems to prefer evenly balanced communities (in terms of number of nodes), while CA does not mind grouping nodes into small communities (like $\\{Flora, Nora, 2/23\\}$)\n\n\n\n::: {#fig-women .cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Three Community Solution (CA)](tm-spectral_files/figure-html/fig-women-1.png){#fig-women-1 width=1152}\n:::\n\n::: {.cell-output-display}\n![Four Community Solution (CA)](tm-spectral_files/figure-html/fig-women-2.png){#fig-women-2 width=1152}\n:::\n\n::: {.cell-output-display}\n![Two Community Solution (Bipartite Modularity)](tm-spectral_files/figure-html/fig-women-3.png){#fig-women-3 width=1152}\n:::\n\n::: {.cell-output-display}\n![Three Community Solution (Bipartite Modularity)](tm-spectral_files/figure-html/fig-women-4.png){#fig-women-4 width=1152}\n:::\n\nSpectral Clustering of Nodes in the Southern Women Data.\n:::\n\n\n## Bipartite Modularity Allowing People and Groups to Belong to Different Number of Communities\n\nOne limitation of Barber's [-@barber07] approach to computing the modularity we have been using to analyze community structure in two-mode networks is that it can only be used under the assumption that the number of communities is the *same* for both persons and groups. \n\nHowever, it could be that the optimal partition is actually one in which the people node set is split into a *different* number of clusters than the group node set. \n\nSo we need a way to evaluate the modularity of a partition when we have different number of communities on the people and group side. \n\nHere's how to do it.\n\nFirst, we generate two separate candidate community assignments for people and groups via spectral clustering from CA using the first six eigenvectors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   k.cuts.p <- k.cuts(CA.res$row$coord[, 1:6])\n   k.cuts.g <- k.cuts(CA.res$col$coord[, 1:6])\n```\n:::\n\n\nAs an example, let's pick the solution that partitions people into four communities and the groups into three communities:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   C.p <- k.cuts.p[[3]]\n   C.g <- k.cuts.g[[2]]\n```\n:::\n\n\nGiven this information, we can create a $4 \\times 3$ matrix recording the proportion of ties in the network that go from person-community $l$ to group-community $m$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   e <- matrix(0, 4, 3)\n   for (l in 1:4) {\n      for (m in 1:3) {\n         e[l, m] = sum(A[C.p == l, C.g == m]) * 1/sum(A)\n      }\n   }\n   round(e, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,] 0.19 0.02 0.17\n[2,] 0.00 0.00 0.04\n[3,] 0.00 0.02 0.02\n[4,] 0.00 0.00 0.53\n```\n:::\n:::\n\n\nFor instance, this matrix says that 53% of the ties in the Southern women data go from people in the fourth community to groups in the third community, according to the CA spectral partition. \n\n@suzuki_wakita09, building on work by @murata09, suggest using the `e` matrix above to compute the modularity of any pair of person/group community assignment according to the following formula:\n\n$$\nQ = \\frac{1}{2}\\sum_{l, m}\\frac{e_{lm}}{e_{l+}}\\left(e_{lm} - e_{l+}e_{+m}\\right)\n$$\n\nWhere $e_{lm}$ is the proportion of edges connecting people in the $l^{th}$ person-community to groups in the $m^{th}$ event-community, $e_{l+}$ is the proportion of edges originating from person-community $i$ (the corresponding entry of the row sum of `e`), and $e_{+m}$ is the proportion of edges originating from nodes in group-community $j$ (the corresponding entry of the column sum of `e`).\n\nSo the idea is that given a partition of the person nodes into $L$ communities and a partition of the group nodes into $M$ communities, we can generate an `e` matrix like the one above and compute the corresponding modularity of that person/group partition using the above equation.\n\nHere's a function that computes the `e` matrix from a pair of person/group partitions and then returns the $Q$ value corresponding to that matrix using the above formula:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   find.mod <- function(w, x, y) {\n      Cx <- max(x)\n      Cy <- max(y)\n      M <- sum(w)\n      e <- matrix(0, Cx, Cy)\n      for (l in 1:Cx) {\n         for (m in 1:Cy) {\n            e[l, m] = sum(w[x == l, y == m]) * 1/M\n         }\n      }\n      Q <- 0\n      a <- rowSums(e)\n      b <- colSums(e)\n      for (l in 1:Cx) {\n         for (m in 1:Cy) {\n            Q <- Q + (e[l, m]/a[l] * (e[l, m] - a[l]*b[m]))\n         }\n      }\n   return(Q/2)\n   }\n```\n:::\n\n\nSo for the `e` matrix from the above example, $Q$ would be:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   find.mod(A,  k.cuts.p[[3]],  k.cuts.g[[2]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.07220939\n```\n:::\n:::\n\n\nWhich looks like a positive number. But is it the biggest of all the possible community partition combinations between people and groups?\n\nTo answer this question, we can use the `find.mod` function to compute the modularity between *every pair* of partitions between people and groups that we calculated earlier. Since we computed eight different partitions for people and groups this leads to $8 \\times 8 = 64$ pairs.\n\nHere's a wrapper function over `find.mod` that computes the corresponding modularity values for each partition pair:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   mod.mat <- function(d) {\n     q <- matrix(0, d, d)\n      for (i in 1:d) {\n         for (j in 1:d) {\n               q[i, j] <- find.mod(A,  k.cuts.p[[i]],  k.cuts.g[[j]])\n         }\n      }\n    return(q)\n   }\n   Q <- round(mod.mat(8), 3)\n   Q\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]\n[1,] 0.102 0.058 0.042 0.031 0.032 0.033 0.029 0.024\n[2,] 0.106 0.066 0.050 0.038 0.039 0.041 0.035 0.033\n[3,] 0.104 0.072 0.056 0.042 0.045 0.043 0.037 0.039\n[4,] 0.112 0.074 0.069 0.055 0.058 0.056 0.050 0.046\n[5,] 0.112 0.075 0.069 0.058 0.061 0.060 0.054 0.050\n[6,] 0.110 0.074 0.075 0.064 0.061 0.063 0.058 0.054\n[7,] 0.111 0.077 0.077 0.066 0.067 0.068 0.062 0.059\n[8,] 0.111 0.077 0.078 0.067 0.067 0.070 0.064 0.060\n```\n:::\n:::\n\n\nInterestingly, the analysis suggests that the maximum modularity $Q = 0.112$ is obtained with a partition of people into five communities and groups into two communities corresponding to cells $(4, 1)$ of the above matrix.\n\nHere's what this community assignment looks like in the Southern Women data:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Spectral Clustering of Nodes in the Southern Women Data with Optimal Community Assignment Obtained via the Suzuki Modularity, with Five Communities for People, Two Communities for Groups.](tm-spectral_files/figure-html/unnamed-chunk-20-1.png){width=1152}\n:::\n:::\n\n\nThe analysis separates two groups of densely connected actors of size six and five, respectively, namely, \\{Brenda, Theresa, Laura, Frances, Evelyn, Eleanor\\} and \\{Katherine, Nora, Sylvia, Myrna, Helen\\} along with their corresponding events from the one another. In the same way, \\{Pearl, Dorothy, Ruth, Verne\\} form a community of more peripheral actors who selectively attend the more popular events; \\{Flora, Olivia\\} are a two-actor community occupying the most peripheral position. Among the core set of actors, \\{Charlotte\\} occupies a singleton-community of her own. \n\nEvents are partitioned into two broad groups: One the one hand, we have those selectively attended by the larger community of densely connected actors along with the most popular events; on the other hand, we have the events selectively attended by the smaller group of densely connected actors. ",
    "supporting": [
      "tm-spectral_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}