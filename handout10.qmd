---
title: "Statistical Models of Networks II"
execute: 
  eval: true
  echo: true
  output: true
  warning: false
  message: false
format: 
   html:
      code-line-numbers: true
---

In this previous handout we saw how to do some basic, single-hypothesis testing against plausible null models. This approach can be thought of as *conditioning* on some set of graph level properties and seeing if something we compute in the graph obtains "net" of these conditioning (e.g., the observed degree distribution). 

Conditining, of course, can be thought of as the analogue of "controlling for" something in a standard linear regression model. This means that it is possible to extend the framework we explored to a setting in which we conditiong on multiple graph properties to see if what we measure obtains "net" of all these properties at th same time.

The framework of **Exponential Random Graph Models** (ERGMs) is useful for this purposes. There are many ways to think of ERGMs, one of them is as a network regression in which we are modeling the probability of observing each tie as a function of a bunch of tie level variables. Another way of thinking about it is as specifying a **dependence structure** that tell us how probability of observing a given tie depends on other things going on in the "neighborhood" of that tie, like whether one of the nodes incident to that edge is also incident to other edges [@pattison_robins12]. 

Formally, this means that an Exponential Random Graph Model is a probabilistic (auto)"regression" model in which the network itself, considered as a random variable ($\mathbf{Y}$) is the main outcome and the specified patterns of local dependence are the main predictors:

$$
    Pr(\mathbf{Y} = \mathbf{y}) = \frac{exp\left[\theta^T S(\mathbf{y})\right] h(\mathbf{y})}{\kappa(\theta)}
$$

This means that the probability of observing a particular realization of the network ($Pr(\mathbf{Y} = \mathbf{y})$) is a function of a given set of local structural configurations defined on the same network ($S(\mathbf{y})$) with the parameter $\theta$ specifying the form of the dependence (e.g., positive or negative) of that local structural factor.^[The denominator ($\kappa(\theta)$) is a normalizing constant required for the expression to result in a proper probability distribution and thus is of no substantive significance.] 

Note that if the we take the natural logarithm of the numerator above it leads to the usual additive linear model expression:

$$
log(exp\left[\theta^T S(\mathbf{y})\right]) = \theta_1s_1(y) + \theta_2s_2(y) + \theta_3s_3(y) + \ldots \theta_ps_p(y)
$$

Where $p$ is the number of terms included in the model. Each $S_p$ is thus a network *statistic* specifying counts of specific configurations (e.g., dyads or triads of a certain type, or links beginning at a particular type of node). When $\theta$ is positive, the existence of a given configuration enhances the probability of observing a link contained in it, while when it is negative $\theta$ is positive, the same configuration depresses the respective probability. 

The whole network, therefore, is seen as being generated by the entire ensemble of local structural mechanisms operating in tandem. This means that each ergm also specifies a probability distribution of graphs that are generated by the model's parameters. 

## Fitting ERGMs

This is all very abstract, so let's see how it works in practice. First, we need a package to estimate ERGMs. Thankfully, there is one, called (predictably) `ergm` (which is dependent on the package `network`):

```{r}
   library(networkdata)
   library(igraph)
   #install.packages("network")
   #install.packages("ergm")
   #install.packages("intergraph")
   library(ergm)
   library(intergraph)
```

Let's bring back the friendship network from Krackhardt's 21 high tech managers:

```{r}
   g <- ht_friends
   g <- as_undirected(g, mode = "collapse")
   n <- asNetwork(g)
```

Note that we use the function `asNetwork` from the `intergraph` package to coerce the `igraph` object into something that the package `ergm` can work with (namely, a `network` object). 

And, now, let's fit an ergm!

```{r}
   m1 <- ergm(n ~ edges)
   summary(m1)
```

The typical structure of an `ergm` call is modeled after the linear regression models `R` functions like `lm` or `glm`, with dependent variable followed by squiggly symbol followed by an additive list of independent variables of the form `y ~ x`.

The output which we can check out by using the function `summary` on the resulting object, is also pretty similar to the typical outputs of linear model functions in `R`. We have a table with the independent variable `edges`, followed by a coefficient estimate, and some kind of p-value against the null hypothesis that that estimate is zero. Which in this case we can reject pretty handily ($Z = - 3.55$, $p < 0.01$).

What is `edges`? Well as we said before, the independent variables in ergm are just counts of stuff that's going on in the network, to predict...the network! 

In this case, `edges` fits the number of edges in the network, which means that it fits anything that is a function of this number, like the **density** (or the **average degree**). 

In fact, the coefficient estimate of the `edges` parameters without any other network covariates *is* the density. 

We can check this as follows, let's transform the coefficient estimate from the logit to the probability scale:

```{r}
   m1$coefficients
   exp(m1$coefficients)/(1 + exp(m1$coefficients))
```

This probability estimate is the same as:

```{r}
   edge_density(g)
```

That is, the expected probability of an edge existing between two randomly chosen nodes in the network, which is the same as the observed density. 

If you like regression analogies, fitting an ergm including only the `edges` parameter and nothing else is equivalent to fitting a linear regression model with only an intercept (which returns the expected value---a.k.a., the mean---of the dependent variable).

As we noted, an ergm model is a model of the network that conditions on the things we put on the right-hand side of the equation, in this case, we conditioned on the density (number of edges), which means that this is an Erdos-Renyi random graph model for the observed network, like the ones we simulated using edge-swapping. 

This also means that we can *simulate* a bunch of networks that condition on the fit of a given ergm. For this we use the function `simulate`:

```{r}
   set.seed(123)
   sim <- simulate(m1, nsim = 100) #generates list of network objects
   sim <- lapply(sim, asIgraph) #converts to list of igraph objects
```

```{r}
#| fig-height: 12
#| fig-width: 12
#| fig-subcap:
#|   - "Original Friendship Network."
#|   - "One ergm simulation."
#|   - "Another ergm simulation."
#|   - "Yet another ergm simulation."
#| layout-ncol: 2
#| echo: false
   set.seed(123)
   plot(g, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25,
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(sim[[1]], 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(sim[[2]], 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(sim[[4]], 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
```

Note that the simulated networks are a **graph ensemble** of networks drawn from a *probability distribution* in which the *expected* (mean) density is equivalent to the observed density.

We can check by looking at the densities of the separate networks:

```{r}
   round(sapply(sim, edge_density), 2)
```

Some of the values are larger and some of them are lower, but they all revolve around the estimate:

```{r}
#| echo: false
   dens <- sapply(sim, edge_density)
   library(ggplot2)
   p <- ggplot(data = data.frame(round(dens, 2)), aes(x = dens))
   p <- p + geom_histogram(binwidth = 0.005, stat = "bin", fill = "darkblue")
   p <- p + geom_vline(xintercept = edge_density(g), 
                       color = "red", linetype = 1, linewidth = 1.5)
   p <- p + theme_minimal() + labs(x = "Density", y = "Freq.")
   p <- p + theme(axis.text = element_text(size = 12))
   p <- p + annotate("text", x= 0.36, y=11, label= "Obs. Density", color = "red")
   p
```

So a useful way to think about ergms is as models that fix *expected* graph statistics in a given ensemble. The values of the expectations are provided by the coefficients obtained in the model for that statistic. 

## Fitting a Real ERGM

Of course, nobody uses the ergm package to fit single parameter Erdo-Renyi random graph models. The point is to test multivariate hypotheses of the type: Is the value of homophily I observe larger than we would expect in a network with these *other* characteristics?

So let's recreate our original analysis of homophily (assortativity) by managerial level from our previous analysis:

```{r}
   m2 <- ergm(n ~ edges + nodematch("level"))
   summary(m2)
```

Here we fit a `nodematch` term with the value of the node-characteristic "level." This term fixes the expected number of dyads that match on this attribute to equal that observed in the network. That is, it adds a "dummy" (change score) indicator if a dyad matches on this attribute. 

The results tell us that, net of density, there is higher likelihood of observing ties that match on this attribute ($\theta = 0.86, p <0.01$).

If we wanted to put a percentage, on this estimate, we could exponentiate:

```{r}
   exp(m2$coefficients[2])
```

Which tells us that there is more than 2 to 1 odds of observing connected dyads that match on level than not. 

As we noted before, it could be that people with some values of the level variable are just more likely to form ties (e.g., the mean degree of nodes varies across the value of levels), so before we conclude that there is a lot of homophily going on, we may want to condition on the *expected* probability of a node with a given value of the level variable to show up at either end of an edge. We can do that like this:

```{r}
   m3 <- ergm(n ~ edges + nodefactor("level", base = 2) + nodematch("level"))
   summary(m3)
```

The ergm term `nodefactor` uses dummy coding for the levels of a given categorical variable and fits $k-1$ terms for mean differences in degree for each category with a category serving as the (omitted) comparison. In this case, we indicate that using the `base` argument, which set the second level category as the reference. 

As we can see, after adjusting for mean differences in degree across levels the assortativity estimate for the `nodematch` term is no longer significant at conventional levels $p = 0.10$, indicating that heterogeneity in connectivity by nodes at different levels partially accounts for this effect (although model fit estimate prefer the more parsimonious model without `nodefactor` level effects).

## Considering Multiple Homophily Effects

Of course, what makes ergms such a flexible modeling system is that we can fit multiple homophily terms at once. In fact, the list of "covariates" can be as long as you want, with the caveat that the more stuff you condition on, the more restricted (and perhaps nonsensical) is the space of graphs that you are presuming your actual data came from. 

Regardless, here's a model with multiple homophily effects, one for levels and the other for "Department":

```{r}
   m4 <- ergm(n ~ edges +  nodematch("level") + nodematch("dept"))
   summary(m4)
```

Which reveals strong homophily effects for each node-level factor "net" of the other one, suggesting that our graph is likely to have come from a world in which nodes form ties selectively based on *both* these criteria. 

## Homophily on a Continous Attribute

Some node attributes like "age" and "tenure" in the Krackhardt's High-Tech Managers data are continuous. Obviously, we couldn't condition on matching on each level of a continuous attribute. 

In the ergm framework homophily on a continuous attribute is handled using the `absdiff` term, which computes the absolute difference in the value of the attribute between the two nodes incident to the edge:

```{r}
   m5 <- ergm(n ~ edges +  nodematch("level") + nodematch("dept")
                  + absdiff("age")
              )
   summary(m5)
```

Which tells us that there is indeed age homophily in this network $\theta_{agediff} = -0.04, p < 0.05$. Note that here a *negative* effect indicates a *smaller* age difference in the tie, which indicates homophily. A positive effect in the `absdiff` term would indicate *heterophily* on the continuous attribute. 

Of course, just like before, we may want to check that we are not mistaking homophily, with the tendency of people in certain age groups to form more ties (e.g., an age/degree correlation in the network). 

To fit the analogue of `nodefactor` for continuous attributes we use `nodecov`, which conditions on the *sum* of the values a given attribute for the two nodes incident to the edge:

```{r}
   m6 <- ergm(n ~ edges +  nodecov("age") + nodematch("level") 
              + nodematch("dept") + absdiff("age")
              )
   summary(m6)
```

Like before, after adjusting for the age/degree correlation, there does not seem to be a statistically significant age homophily effect ($p = 0.20$). 

Finally, here's a model including homophily effects for all four node attributes (two categorical and two continuous) in the Krackhardt High-Tech Managers data:

```{r}
   m7 <- ergm(n ~ edges +  nodecov("age") + nodecov("tenure")
              + nodematch("level") + nodematch("dept")  
              + absdiff("age") + absdiff("tenure")
              )
   summary(m7)
```

Note that this model also conditions on the degree correlation between tenure at the firm and degree. As we can see, the categorical homophily effects due to level and department remain strong, however, there is no evidence for homophily effects based on age and tenure. 

Instead, the continuous attributes are correlated with degree, with ties featuring younger people being more likely to be observed (negative age effect on the `nodecov` term) and ties featuring people with longer tenure (positive tenure effect on the `nodecov` term) also being more likely to be observed. It makes sense to condition on both age and tenure at the same time, since these are strongly correlated at the individual level ($r=$ `r round(cor(V(g)$age, V(g)$tenure), 2)`)

## Heterogeneous Homiphily Effects

Note that `nodematch` fits a single term for the homophily on a categorical attribute. For an attribute with just two categories this may not be a problem, since we are just comparing "same" connected dyads to "different" connected dyads.

But consider an attribute like "department" in these data, which has four levels. Fitting a single term means we are constraining the homophily effect to be the same regardless of the levels at which the nodes match. So the effect for 4-4 nodes is the same as the effect for 3-3 nodes, which is the same as the effect for 2-2 nodes and so forth. 

We can of course relax this homogeneity restriction and specify *separate* `nodematch` effects by levels of the categorical attribute:


```{r}
   m8 <- ergm(n ~ edges +  nodecov("age") + nodecov("tenure")
              + nodematch("level") 
              + nodematch("dept", diff = TRUE, levels = c(2, 3, 4))  
              + absdiff("age") + absdiff("tenure")
              )
   summary(m8)
```

Here we are using connected dyads that match at department = 1 in the data (there's one node that is coded at zero on this variable, so there cannot be dyads that match at this value) as the reference by specifying the `levels` argument. We specify we want heterogeneous homophily effects by department by setting the `diff` argument inside the `nodematch` term to `TRUE` (it is `FALSE` by default).

As we can see, we can observe heterogeneous homophily effects on the department attribute in these data. Connected dyads matching on department at levels 2 and 3 are responsible for most of the positive homophily effects. For dyads that match at level 4 of department, there is no homophily ($\theta_{dept4-4} = - 0.35, p = 0.80$). 


