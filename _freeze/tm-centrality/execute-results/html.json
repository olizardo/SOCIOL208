{
  "hash": "d5a91dcfc31726d86e72bfaff7ede657",
  "result": {
    "markdown": "---\ntitle: \"Centrality in Two-Mode Networks\"\nexecute: \n  eval: true\n  echo: true\n  output: true\n  warning: false\n  message: false\nformat: \n   html:\n      code-line-numbers: true\n---\n\n\nWe have already seen how to calculate the simplest measure of centrality in two-mode networks (degree) in the [basic two-mode statistics](two-mode.qmd) lecture. Here we extend the discussion to the other two of the big three, **closeness** and **betwennness**. As always, we load up the usual *Southern Women* (SW) data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    library(igraph)\n    library(networkdata)\n    g <- southern_women\n    A <- as_biadjacency_matrix(g)\n```\n:::\n\n\n## Geodesic Distances\n\nGeodesic distances work a bit different in two-mode networks because of the only between-node-sets edges restriction. \n\nFor instance, the minimum geodesic distance $g_{ii'}$ between two people is two (a person cannot be adjacent to another person), but it is one between a person and a group (if the person is a member of the group). \n\nIn the same way, a group $g$ cannot be at geodesic distance less than three from a person $p*$ who is not a member, because the shortest path is $g-p-g^*-p^*$. \n\nThat is, there has to be some other group $g^*$ shared between a member $p$ of the focal group $g$ and another person $p^*$ for the shortest path between $g$ and the non-member $p^*$ to exist, and that involves three links at minimum: $g-p$, $p-g^*$, and $g^*-p^*$. This means that the links in paths in two-mode networks always alternate between persons and group nodes.\n\nBeyond that geodesic distances work the same way. In `igraph` when we use the `distances` function on a bipartite graph, we get:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   D.pg <- distances(g)\n   head(D.pg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          EVELYN LAURA THERESA BRENDA CHARLOTTE FRANCES ELEANOR PEARL RUTH\nEVELYN         0     2       2      2         2       2       2     2    2\nLAURA          2     0       2      2         2       2       2     2    2\nTHERESA        2     2       0      2         2       2       2     2    2\nBRENDA         2     2       2      0         2       2       2     2    2\nCHARLOTTE      2     2       2      2         0       2       2     4    2\nFRANCES        2     2       2      2         2       0       2     2    2\n          VERNE MYRNA KATHERINE SYLVIA NORA HELEN DOROTHY OLIVIA FLORA 6/27 3/2\nEVELYN        2     2         2      2    2     2       2      2     2    1   1\nLAURA         2     2         2      2    2     2       2      4     4    1   1\nTHERESA       2     2         2      2    2     2       2      2     2    3   1\nBRENDA        2     2         2      2    2     2       2      4     4    1   3\nCHARLOTTE     2     4         4      2    2     2       4      4     4    3   3\nFRANCES       2     2         2      2    2     2       2      4     4    3   3\n          4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       1    1    1    1    3    1   1    3    3   3     3   3\nLAURA        1    3    1    1    1    1   3    3    3   3     3   3\nTHERESA      1    1    1    1    1    1   1    3    3   3     3   3\nBRENDA       1    1    1    1    1    1   3    3    3   3     3   3\nCHARLOTTE    1    1    1    3    1    3   3    3    3   3     3   3\nFRANCES      1    3    1    1    3    1   3    3    3   3     3   3\n```\n:::\n\n```{.r .cell-code}\n   tail(D.pg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      EVELYN LAURA THERESA BRENDA CHARLOTTE FRANCES ELEANOR PEARL RUTH VERNE\n4/8        1     3       1      3         3       3       3     1    1     1\n6/10       3     3       3      3         3       3       3     3    3     3\n2/23       3     3       3      3         3       3       3     3    3     3\n4/7        3     3       3      3         3       3       3     3    3     1\n11/21      3     3       3      3         3       3       3     3    3     3\n8/3        3     3       3      3         3       3       3     3    3     3\n      MYRNA KATHERINE SYLVIA NORA HELEN DOROTHY OLIVIA FLORA 6/27 3/2 4/12 9/26\n4/8       1         1      1    1     3       1      1     1    2   2    2    2\n6/10      1         1      1    1     1       3      3     3    4   4    4    4\n2/23      3         3      3    1     1       3      1     1    4   4    4    4\n4/7       1         1      1    1     1       3      3     3    4   4    4    4\n11/21     3         1      1    1     3       3      3     3    4   4    4    4\n8/3       3         1      1    1     3       3      3     3    4   4    4    4\n      2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\n4/8      2    2    2    2   0    2    2   2     2   2\n6/10     4    2    2    2   2    0    2   2     2   2\n2/23     4    2    2    2   2    2    0   2     2   2\n4/7      4    2    2    2   2    2    2   0     2   2\n11/21    4    2    2    2   2    2    2   2     0   2\n8/3      4    2    2    2   2    2    2   2     2   0\n```\n:::\n:::\n\n\nWhich is a square matrix of dimensions $(M + N) \\times (M + N)$; that's $(18 + 14) \\times (18 + 14) = 32 \\times 32$ in our case. \n\nWe can check in `R`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   dim(D.pg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 32 32\n```\n:::\n:::\n\n\nAs we can see in the distance matrix, distances between nodes in the same set are even $g_{ii'|jj'} = \\{2, 4, \\ldots\\}$ but distances in nodes in different sets are odd $g_{ij|ji} = \\{1, 3, \\ldots\\}$. Beyond this hiccup, distances can be interpreted in the same way as one-mode networks.\n\n## Closeness Centrality \n\nThis means that (unnormalized) closeness centrality works the same way as it does in regular networks:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(closeness(g), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n    0.017     0.015     0.017     0.015     0.013     0.014     0.014     0.014 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n    0.015     0.015     0.014     0.015     0.016     0.017     0.015     0.014 \n   OLIVIA     FLORA      6/27       3/2      4/12      9/26      2/25      5/19 \n    0.012     0.012     0.012     0.012     0.013     0.012     0.014     0.016 \n     3/15      9/16       4/8      6/10      2/23       4/7     11/21       8/3 \n    0.017     0.019     0.018     0.013     0.012     0.013     0.012     0.012 \n```\n:::\n:::\n\n\nWhich is just the inverse of the sums of the distances matrix for people and groups counting their geodesic distances to nodes of both sets. \n\nHowever, as @borgatti_everett97 note, if we want *normalized* closeness centralities, we can't use the off-the-shelf normalization for one-mode networks in `igraph` ($n-1$) as it will give us non-sense results because now we have two sets of nodes.\n\nInstead, we need to normalize the closeness score for each node set by its theoretical maximum for each node set. \n\nFor people, this is:\n\n$$\nN + 2(M - 1)\n$$\n\nAnd for groups/events this same quantity is:\n\n$$\nM + 2(N - 1)\n$$\n\nThe basic idea is that nodes can be at minimum geodesic distance $g = 1$ from nodes of the other set (for people, groups; for groups, people) and at minimum distance $g = 2$ from nodes of their own set, with their own presence eliminated by subtraction [@borgatti_everett97]. \n\nIn our case, we create a normalization vector with these quantities of length $M + N$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   M <- nrow(A)\n   N <- ncol(A)\n   n.p <- N + 2 * (M - 1)\n   n.e <- M + 2 * (N - 1)\n   norm.vec <- c(rep(n.p, M), rep(n.e, N))\n```\n:::\n\n\nAnd normalized closeness is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(norm.vec/rowSums(D.pg), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n    0.800     0.727     0.800     0.727     0.600     0.667     0.667     0.667 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n    0.706     0.706     0.686     0.727     0.774     0.800     0.727     0.649 \n   OLIVIA     FLORA      6/27       3/2      4/12      9/26      2/25      5/19 \n    0.585     0.585     0.524     0.524     0.564     0.537     0.595     0.688 \n     3/15      9/16       4/8      6/10      2/23       4/7     11/21       8/3 \n    0.733     0.846     0.786     0.550     0.537     0.564     0.524     0.524 \n```\n:::\n:::\n\n\nWhich are the same numbers in @borgatti_everett97 [table 1, column 6].\n\n## Betweenness Centrality \n\nAs @borgatti_everett97 also note, the normalizations for betweenness centrality in the two-mode case are a bit more involved. This is because they depend on which node set is larger than the other. \n\nFor the larger node set, which in our case is the people, the normalization is:\n\n$$\n2(M-1)(N-1)\n$$\n\nFor the smaller node set, which in our case is the groups/events, the normalization is:\n\n$$\n\\frac{1}{2}(N)(N-1)+\\frac{1}{2}(M-1)(M-2)+(M-1)(N-1)\n$$\n\nRemember that you have to switch this around if you are analyzing a network with more groups than people. \n\nCreating the relevant vectors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   n.p <- 2*(M-1)*(N-1)\n   n.e <- (1/2)*(N*(N-1))+(1/2)*(M-1)*(M-2)+(M-1)*(N-1)\n   norm.vec <- c(rep(n.p, M), rep(n.e, N))\n```\n:::\n\n\nAnd normalized betweenness is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(betweenness(g)/norm.vec, 4)*100\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n     9.72      5.17      8.82      4.98      1.07      1.08      0.95      0.68 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n     1.69      1.58      1.65      4.77      7.22     11.42      4.27      0.20 \n   OLIVIA     FLORA      6/27       3/2      4/12      9/26      2/25      5/19 \n     0.51      0.51      0.22      0.21      1.84      0.78      3.80      6.56 \n     3/15      9/16       4/8      6/10      2/23       4/7     11/21       8/3 \n    13.07     24.60     22.75      1.15      1.98      1.83      0.23      0.23 \n```\n:::\n:::\n\n\nWhich are (with some slight differences and rounding errors) the same numbers in @borgatti_everett97 [table 2, column 3].",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}