---
title: "Statistical Models of Networks II"
execute: 
  eval: true
  echo: true
  output: true
  warning: false
  message: false
format: 
   html:
      code-line-numbers: true
---

In this previous handout we saw how to do some basic, single-hypothesis testing against plausible null models. This approach can be thought of as *conditioning* on some set of graph level properties and seeing if something we compute in the graph obtains "net" of these conditioning (e.g., the observed degree distribution). 

Conditioning, of course, can be thought of as the analogue of "controlling for" something in a standard linear regression model. This means that it is possible to extend the framework we explored to a setting in which we conditioning on multiple graph properties to see if what we measure obtains "net" of all these properties at th same time.

## Exponential Random Graph Models

The framework of **Exponential Random Graph Models** (ERGMs) is useful for this purposes. There are many ways to think of ERGMs, one of them is as a network regression in which we are modeling the probability of observing each tie as a function of a bunch of tie level variables. Another way of thinking about it is as specifying a **dependence structure** that tell us how probability of observing a given tie depends on other things going on in the "neighborhood" of that tie, like whether one of the nodes incident to that edge is also incident to other edges [@pattison_robins12]. 

Formally, this means that an Exponential Random Graph Model is a probabilistic (auto)"regression" model in which the network itself, considered as a random variable ($\mathbf{Y}$) is the main outcome and the specified patterns of local dependence are the main predictors:

$$
    Pr(\mathbf{Y} = \mathbf{y}) = \frac{exp\left[\theta^T S(\mathbf{y})\right] h(\mathbf{y})}{\kappa(\theta)}
$$

This means that the probability of observing a particular realization of the network ($Pr(\mathbf{Y} = \mathbf{y})$) is a function of a given set of local structural configurations defined on the same network ($S(\mathbf{y})$) with the parameter $\theta$ specifying the form of the dependence (e.g., positive or negative) of that local structural factor.^[The denominator ($\kappa(\theta)$) is a normalizing constant required for the expression to result in a proper probability distribution and thus is of no substantive significance.] 

Note that if the we take the natural logarithm of the numerator above it leads to the usual additive linear model expression:

$$
log(exp\left[\theta^T S(\mathbf{y})\right]) = \theta_1s_1(y) + \theta_2s_2(y) + \theta_3s_3(y) + \ldots \theta_ps_p(y)
$$

Where $p$ is the number of terms included in the model. Each $S_p$ is thus a network *statistic* specifying counts of specific configurations (e.g., dyads or triads of a certain type, or links beginning at a particular type of node). When $\theta$ is positive, the existence of a given configuration enhances the probability of observing a link contained in it, while when it is negative $\theta$ is positive, the same configuration depresses the respective probability. 

The whole network, therefore, is seen as being generated by the entire ensemble of local structural mechanisms operating in tandem. This means that each ergm also specifies a probability distribution of graphs that are generated by the model's parameters. 

## Fitting ERGMs

This is all very abstract, so let's see how it works in practice. First, we need a package to estimate ERGMs. Thankfully, there is one, called (predictably) `ergm` (which is dependent on the package `network`):

```{r}
   library(networkdata)
   library(igraph)
   #install.packages("network")
   #install.packages("ergm")
   #install.packages("intergraph")
   library(ergm)
   library(intergraph)
```

Let's bring back the friendship network from Krackhardt's 21 high tech managers:

```{r}
   g <- ht_friends
   g <- as_undirected(g, mode = "collapse")
   n <- asNetwork(g)
```

Note that we use the function `asNetwork` from the `intergraph` package to coerce the `igraph` object into something that the package `ergm` can work with (namely, a `network` object). 

And, now, let's fit an ergm!

```{r}
   m1 <- ergm(n ~ edges)
   summary(m1)
```

The typical structure of an `ergm` call is modeled after the linear regression models `R` functions like `lm` or `glm`, with dependent variable followed by squiggly symbol followed by an additive list of independent variables of the form `y ~ x`.

The output which we can check out by using the function `summary` on the resulting object, is also pretty similar to the typical outputs of linear model functions in `R`. We have a table with the independent variable `edges`, followed by a coefficient estimate, and some kind of p-value against the null hypothesis that that estimate is zero. Which in this case we can reject pretty handily ($Z = - 3.55$, $p < 0.01$).

What is `edges`? Well as we said before, the independent variables in ergm are just counts of stuff that's going on in the network, to predict...the network! 

In this case, `edges` fits the number of edges in the network, which means that it fits anything that is a function of this number, like the **density** (or the **average degree**). 

In fact, the coefficient estimate of the `edges` parameters without any other network covariates *is* the density. 

We can check this as follows, let's transform the coefficient estimate from the logit to the probability scale:

```{r}
   m1$coefficients
   exp(m1$coefficients)/(1 + exp(m1$coefficients))
```

This probability estimate is the same as:

```{r}
   edge_density(g)
```

That is, the expected probability of an edge existing between two randomly chosen nodes in the network, which is the same as the observed density. 

If you like regression analogies, fitting an ergm including only the `edges` parameter and nothing else is equivalent to fitting a linear regression model with only an intercept (which returns the expected value---a.k.a., the mean---of the dependent variable).

As we noted, an ergm model is a model of the network that conditions on the things we put on the right-hand side of the equation, in this case, we conditioned on the density (number of edges), which means that this is an Erdos-Renyi random graph model for the observed network, like the ones we simulated using edge-swapping. 

This also means that we can *simulate* a bunch of networks that condition on the fit of a given ergm. For this we use the function `simulate`:

```{r}
   set.seed(123)
   sim <- simulate(m1, nsim = 100) #generates list of network objects
   sim <- lapply(sim, asIgraph) #converts to list of igraph objects
```

```{r}
#| fig-height: 12
#| fig-width: 12
#| fig-subcap:
#|   - "Original Friendship Network."
#|   - "One ergm simulation."
#|   - "Another ergm simulation."
#|   - "Yet another ergm simulation."
#| layout-ncol: 2
#| echo: false
   set.seed(123)
   plot(g, 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25,
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(sim[[1]], 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(sim[[2]], 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
   
   set.seed(123)
   plot(sim[[4]], 
     vertex.size=6, vertex.frame.color="blue", edge.color = "blue",
     vertex.label.cex = 2, edge.arrow.size = 0.25, 
     vertex.label.color = "red",
     vertex.label.dist=1.5, edge.curved=0.2)
```

Note that the simulated networks are a **graph ensemble** of networks drawn from a *probability distribution* in which the *expected* (mean) density is equivalent to the observed density.

We can check by looking at the densities of the separate networks:

```{r}
   dens <- sapply(sim, edge_density)
   round(dens, 2)
```

Some of the values are larger and some of them are lower, but they all revolve around the estimate:

```{r}
#| echo: false
   m <- mean(dens)
   min <- min(round(dens, 2))
   max <- max(round(dens, 2))
   library(ggplot2)
   m <- mean(sapply(sim, edge_density))
   p <- ggplot(data = data.frame(round(dens, 2)), aes(x = dens))
   p <- p + geom_histogram(binwidth = 0.005, stat = "bin", fill = "darkblue")
   p <- p + geom_vline(xintercept = m, 
                       color = "red", linetype = 1, linewidth = 1.5)
   p <- p + geom_vline(xintercept = edge_density(g), 
                       color = "purple", linetype = 1, linewidth = 1.5)
   p <- p + theme_minimal() + labs(x = "Density", y = "Freq.")
   p <- p + theme(axis.text = element_text(size = 12))
   p <- p + scale_x_continuous(breaks = seq(min, max, 0.02))
   p <- p + annotate("text", x= 0.395, y=11, label= "Obs. Density", color = "red")
   p <- p + annotate("text", x= 0.355, y=11, label= "Ensemble Avg.", color = "purple")

   p
```

If we take larger and larger graph ensembles the distribution of densities would become bell-shaped and the average of the ensemble would converge around the density of the observed network. 

So a useful way to think about ergms is as models that fix *expected* graph statistics in a given ensemble. The values of the expectations are provided by the coefficients obtained in the model for that statistic, and the range of possible variation around those expectations are given by the standard error of the estimate. 

## Fitting a Real ERGM

Of course, nobody uses the ergm package to fit single parameter Erdo-Renyi random graph models. The point is to test multivariate hypotheses of the type: Is the value of a given network effect (e.g., homophily) I observe larger or smaller than we would expect in a network with these *other* characteristics?

So let's recreate our original analysis of homophily (assortativity) by managerial level from our previous analysis:

```{r}
   m2 <- ergm(n ~ edges + nodematch("level"))
   summary(m2)
```

Here we fit a `nodematch` term with the value of the node-characteristic "level." This term fixes the expected number of dyads that match on this attribute to equal that observed in the network. That is, it adds a "dummy" (change score) indicator if a dyad matches on this attribute. 

The results tell us that, net of density, there is higher likelihood of observing ties that match on this attribute ($\theta = 0.86, p <0.01$).

If we wanted to put a percentage, on this estimate, we could exponentiate:

```{r}
   exp(m2$coefficients[2])
```

Which tells us that there is more than 2 to 1 odds of observing connected dyads that match on level than not. 

## Activity Differences Based on a Categorical Factor

As we noted before, it could be that people with some values of the level variable are just more likely to form ties (e.g., the mean degree of nodes varies across the value of levels), so before we conclude that there is a lot of homophily going on, we may want to condition on the *expected* probability of a node with a given value of the level variable to show up at either end of an edge. We can do that like this:

```{r}
   m3 <- ergm(n ~ edges + nodefactor("level", base = 2) + nodematch("level"))
   summary(m3)
```

The ergm term `nodefactor` uses dummy coding for the levels of a given categorical variable and fits $k-1$ terms for mean differences in degree for each category with a category serving as the (omitted) comparison. In this case, we indicate that using the `base` argument, which set the second level category as the reference. 

As we can see, after adjusting for mean differences in degree across levels the assortativity estimate for the `nodematch` term is no longer significant at conventional levels $p = 0.10$, indicating that heterogeneity in connectivity by nodes at different levels partially accounts for this effect (although model fit estimate prefer the more parsimonious model without `nodefactor` level effects).

## Considering Multiple Homophily Effects

Of course, what makes ergms such a flexible modeling system is that we can fit multiple homophily terms at once. In fact, the list of "covariates" can be as long as you want, with the caveat that the more stuff you condition on, the more restricted (and perhaps nonsensical) is the space of graphs that you are presuming your actual data came from. 

Regardless, here's a model with multiple homophily effects, one for levels and the other for "Department":

```{r}
   m4 <- ergm(n ~ edges +  nodematch("level") + nodematch("dept"))
   summary(m4)
```

Which reveals strong homophily effects for each node-level factor "net" of the other one, suggesting that our graph is likely to have come from a world in which nodes form ties selectively based on *both* these criteria. 

## Homophily on a Continuous Attribute

Some node attributes like "age" and "tenure" in the Krackhardt's High-Tech Managers data are continuous. Obviously, we couldn't condition on matching on each level of a continuous attribute. 

In the ergm framework homophily on a continuous attribute is handled using the `absdiff` term, which computes the absolute difference in the value of the attribute between the two nodes incident to the edge:

```{r}
   m5 <- ergm(n ~ edges 
              +  nodematch("level") + nodematch("dept")
              + absdiff("age")
              )
   summary(m5)
```

Which tells us that there is indeed age homophily in this network $\theta_{agediff} = -0.04, p < 0.05$. Note that here a *negative* effect indicates a *smaller* age difference in the tie, which indicates homophily. A positive effect in the `absdiff` term would indicate *heterophily* on the continuous attribute. 

## Activity Differences Based on a Continuous Factor
Of course, just like before, we may want to check that we are not mistaking homophily, with the tendency of people in certain age groups to form more ties in general (e.g., an age/degree correlation in the network). 

To fit the analogue of `nodefactor` for continuous attributes we use `nodecov`, which conditions on the *sum* of the values a given attribute for the two nodes incident to the edge:

```{r}
   m6 <- ergm(n ~ edges 
              +  nodecov("age") + nodematch("level") 
              + nodematch("dept") + absdiff("age")
              )
   summary(m6)
```

Like before, after adjusting for the age/degree correlation, there does not seem to be a statistically significant age homophily effect ($p = 0.20$). 

Finally, here's a model including homophily effects for all four node attributes (two categorical and two continuous) in the Krackhardt High-Tech Managers data:

```{r}
   m7 <- ergm(n ~ edges 
              +  nodecov("age") + nodecov("tenure")
              + nodematch("level") + nodematch("dept")  
              + absdiff("age") + absdiff("tenure")
              )
   summary(m7)
```

Note that this model also conditions on the degree correlation between tenure at the firm and degree. As we can see, the categorical homophily effects due to level and department remain strong, however, there is no evidence for homophily effects based on age and tenure. 

Instead, the continuous attributes are correlated with degree, with ties featuring younger people being more likely to be observed (negative age effect on the `nodecov` term) and ties featuring people with longer tenure (positive tenure effect on the `nodecov` term) also being more likely to be observed. It makes sense to condition on both age and tenure at the same time, since these are strongly correlated at the individual level ($r=$ `r round(cor(V(g)$age, V(g)$tenure), 2)`)

## Heterogeneous Homophily Effects

Note that `nodematch` fits a single term for the homophily on a categorical attribute. For an attribute with just two categories this may not be a problem, since we are just comparing "same" connected dyads to "different" connected dyads.

But consider an attribute like "department" in these data, which has four levels. Fitting a single term means we are constraining the homophily effect to be the same regardless of the levels at which the nodes match. So the effect for 4-4 nodes is the same as the effect for 3-3 nodes, which is the same as the effect for 2-2 nodes and so forth. 

We can of course relax this homogeneity restriction and specify *separate* `nodematch` effects by levels of the categorical attribute:


```{r}
   m8 <- ergm(n ~ edges 
              + nodecov("age") + nodecov("tenure")
              + nodematch("level", levels = c(2, 3)) 
              + nodematch("dept", diff = TRUE, levels = c(2, 3, 4))  
              + absdiff("age") + absdiff("tenure") 
              )
   summary(m8)
```

Here we are using connected dyads that match at department = 1 in the data (there's one node that is coded at zero on this variable, so there cannot be dyads that match at this value) as the reference by specifying the `levels` argument. We specify we want heterogeneous homophily effects by department by setting the `diff` argument inside the `nodematch` term to `TRUE` (it is `FALSE` by default).

As we can see, we can observe heterogeneous homophily effects on the department attribute in these data. Connected dyads matching on department at levels 2 and 3 are responsible for most of the positive homophily effects. For dyads that match at level 4 of department, there is no homophily ($\theta_{dept4-4} = - 0.35, p = 0.80$). 

## Looking at combinations of ties featuring an attribute

In the preceding we looked at terms that condition on *homophily* or the probability that a given edge in a network drawn at random would feature nodes that *match* on a given attribute. Sometimes, we may be interested in looking at terms that condition on both matching and not-matching. For this task, we use the `ergm` term `nodemix`.

Let's look at an example. But first let's switch to a different data set, this time the friendship nomination network from Lazega's Law Firm data:

```{r}
   g <- law_friends
   g <- as_undirected(g, mode = "collapse")
   n <- asNetwork(g)
```

And now let's fit an ergm that conditions on homophily and activity effects for four individual level covariates:  gender, partner status, age, seniority.

```{r}
   m9 <- ergm(n ~ edges + 
                  + nodecov("age") + nodecov("seniority")
                  + nodefactor("status") + nodefactor("gender")
                  + nodematch("status") + nodematch("gender")
                  + absdiff("age") + absdiff("seniority")
              )
   summary(m9)
```

We can see that there are not statistically significant activity effects based on attribute, except for the one premised on status in the firm (although both the positive seniority and gender effects are significant at the $p <0.10$ level. We can also observe predicted homophily effects based on all four characteristics. This looks like a well-fitting useful baseline model.

Let's now add additional activity and homophily effects `law_school`. This variable is coded into three categories: (1) Harvard/Yale, (2) Uconn, (3) "Other":

```{r}
   m10 <- ergm(n ~ edges +
                  + nodecov("age") + nodecov("seniority")
                  + nodefactor("status") + nodefactor("gender")
                  + nodefactor("law_school", base = 3)
                  + nodematch("status") + nodematch("gender")
                  + absdiff("age") + absdiff("seniority")
                  + nodematch("law_school")
              )
   summary(m10)
```

This model shows that Uconn graduates are more popular in the friendship network (they form  more ties), compared to graduates from "other" schools, but that there  doesn't seem to be homophily based on this factor. 


## Homophily via Combination of Attributes

Sometimes we may suspect that homophily happens via a *combination* of attributes (e.g., gender and status). We can specify such effects using the `nodemix` term as follows:

```{r}
   m11 <- ergm(n ~ edges +
                  + nodecov("age") + nodecov("seniority")
                  + nodefactor("status") + nodefactor("gender")
                  + nodefactor("law_school", base = 3)
                  + absdiff("age") + absdiff("seniority")
                  + nodematch("law_school")
                  + nodemix(c("gender", "status"), levels = TRUE, levels2 = c(1:6))
              )
   summary(m11)
```

Here we use low status homogeneous dyads (regardless of gender mix) as the comparison category. The results show that compared to those dyads, high-status homogeneous, all men dyads are more prevalent, as gender-mixed dyads where the man is higher status. We also find a preponderance of all-men, status heterogeneous dyads. 

## Checking for Model Fit

In  ergms we can always check for model fit using standard statistics they share with general linear models, like the model deviance, BIC, AIC and so forth. These are particularly useful when trying to decide between nested models.

However, we can also use the fact that each ergm specifies a *probability distribution* across a graph ensemble consistent with the estimated parameters to see whether the specification we decided on actually produces graphs with global (network level) characteristics that fall within a plausible range. 

That is, even though network level factors are not directly specified in the model, a good model should be able to reproduce them via the local tie generating processes we specified. 

When an ergm specification does not do this, and instead produces graphs within a narrow or weird range of values---e.g., for basic network statistics like the degree distribution, the geodesic distance distribution, or basic counts of key motifs like triangles and number of shared partners (a technical issue known as "degeneracy" in the ergm framework)---then that is a signal we need to change something in our specification. 

In the `ergm` package we can check for goodness of fit based on the ability to match global network characteristics using the `gof` function. The function takes a `ergm` model object as input along with an optional argument called `GOF` specifying what simulated global network property across the implied graph ensemble we want to compare to our observed values. The main ones include the degree distribution, the distribution of edge-wise shared partners (common neighbors of connected dyads), and the geodesic distance distribution (number of dyads separated by shortest parths of a given length).

Let's use `m8` above which was the attribute-driven model with heterogeneous homophily effects for department we fit to the Krackhardt High Tech Managers data. Let's say, we wanted to see whether our model was successful in reproducing the distribution of activity (degree) across nodes. In that case, we would type:

```{r}
   set.seed(123)
   gof.m8 <- gof(m8, GOF = ~ degree)
```

Here we asked `gof` to create a graph ensemble of one hundred graphs (the default) and look at the degree distribution in each, recording how many times a node with a given degree is observed in each graph. 

To see the result we can check out the following object:

```{r}
   gof.m8$pval.deg
```

The way to read the table is as follows: Under the column "obs" is the values of degree in the data (observed), then the other columns contain the range (min and max) and the mean of the each value of degree in the graph ensemble implied by the model. 

The p-value is a test that the observed value is significantly different from the *mean* of the graph ensemble. Note that in a good fitting model, *the mean of the ensemble implied by the model* so we want $p > 0.05$ for each row in the table as this indicates a *good fitting model*. 
We can see that this is indeed the case for every value except the last outlier one ($k = 18$), the simulations show this never happening (max = 0), so it is outside of the range of the observed value of one ($p = 0.00$).

Overall, however, the model does a good job of reproducing a distribution of degrees in the ensemble consistent with the observed data. If we wanted to see it in a plot, we would just type:

```{r}
   plot(gof.m8)
```

In this box plot, the ensemble mean is the blue diamond, the gray box is the interquartile (25th to 75th percentile) range, the black horizontal line in the gray box is the ensemble median, and the black connected line plot is the observed values. 

What we would like to see in a well-fitting model is a black line that goes through the gray box and is not outside them, which is generally the case here for most of the observed range except for the very large values. 

## Conditioning on Degree and Shared Partners

Note that all the models estimated earlier only adjust for the edges parameter as a structural effect. In this sense, they are using the Erdos-Renyi model as the structural baseline.

As we saw with the edge swapping models, it is probably better to use more sophisticated null models than the Erdos-Renyi one. For instance, models that condition on degree heterogeneity in some way, or that also account for transitivity (e.g., triangle) effects (e.g., the tendency of dyads sharing common partners to be connected).

In an ergm context, we could condition on the degree distribution by adding a separate parameter for each observed degree, or adding a `triangle` term. These models are computationally intensive, and often fail to converge (for obscure technical reasons).

A better approach is to fit both degree heterogeneity and transitivity effect using a family of **geometrically weighted decay parameter** terms. The idea is to fit the distribution of a given quantity (e.g., degree, number of shared partners per dyad) by fitting a curve with a term that decays as either the degree or the number of shared partners increases, thus giving more weight to lower degrees and the first or second shared partner as compared to the third, fourth, fifth, and so forth.

These `gw` terms are less computationally intensive and use a single parameter to fit both the degree distribution---using the `gwdegree` term---and the (dyad or edge)wise shared partner distribution---using the `gwdsp` and `gwesp` terms (respectively).

Let's see how the `gw` ergm terms work, going back to Krackhardt's High Tech Managers data. Here's a model looking at activity and homophily effects conditioning on the degree distribution:

```{r}
   g <- ht_friends
   g <- as_undirected(g, mode = "collapse")
   n <- asNetwork(g)
   m12 <- ergm(n ~ edges 
              + nodecov("age") + nodecov("tenure")
              + nodematch("level", levels = c(2, 3)) 
              + nodematch("dept", diff = TRUE, levels = c(2, 3, 4))  
              + absdiff("age") + absdiff("tenure") 
              + gwdegree(decay = 0.25, fixed = TRUE)
              )
   summary(m12)
```

Note that our homophily estimates are still significant, even after accounting for heterogeneity in the degree distribution, the estimate of corresponding to the `gwdegree` term is not significant, suggesting that our activity and homophily attributes do a good job of fitting the empirical degree distribution (which we knew form  our goodness of fit tests). 

Now, here's a model that conditions on the tendency for dyads who share common partners to themselves be connected:

```{r}
   g <- ht_friends
   g <- as_undirected(g, mode = "collapse")
   n <- asNetwork(g)
   m12 <- ergm(n ~ edges 
              + nodecov("age") + nodecov("tenure")
              + nodematch("level", levels = c(2, 3)) 
              + nodematch("dept", diff = TRUE, levels = c(2, 3, 4))  
              + absdiff("age") + absdiff("tenure") 
              + gwdsp(decay = 0.25, fixed = TRUE)
              )
   summary(m12)
```

In this model, we find a statistically significant $\theta$ estimate for the **geometrically weighted dyadwise shared partners** effect (with decay parameter $\gamma = 0.25$), suggesting that this network is likely drawn from a distribution of graphs where pairs of nodes mutually connected to a third are also more likely to be connected themselves ($p < 0.05$). 

However, even after adjusting for this structural tendency our homophily effects are still statistically significant, suggesting that they are not the spurious byproduct of transitivity in friendship ties. 

Finally, we can also adjust for the tendency of connected dyads to share multiple friends (e.g., connected dyads being embedded on one or more triangles), also known as the **Simmelian Tie** effect, also known as the **geometrically weighted edgewise shared partners** effect:

```{r}
   g <- ht_friends
   g <- as_undirected(g, mode = "collapse")
   n <- asNetwork(g)
   m13 <- ergm(n ~ edges 
              + nodecov("age") + nodecov("tenure")
              + nodematch("level", levels = c(2, 3)) 
              + nodematch("dept", diff = TRUE, levels = c(2, 3, 4))  
              + absdiff("age") + absdiff("tenure") 
              + gwdsp(decay = 0.25, fixed = TRUE)
              + gwesp(decay = 0.25, fixed = TRUE)
              )
   summary(m13)
```

Which shows that our results are also robust to this structural tendency, although the transitivity effect is weakened a bit ($p < 0.10$) when adjusting for statistical prevalence of Simmelian ties.


