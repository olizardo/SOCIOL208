{
  "hash": "ff0830abdde03635c0eb5d724d3cb1d7",
  "result": {
    "markdown": "---\ntitle: \"Closeness Centrality\"\nexecute: \n  eval: true\n  echo: true\n  output: true\n  warning: false\n  message: false\nformat: \n   html:\n      code-line-numbers: true\n---\n\n\nThe **closeness centrality** of a node in a graph is defined as the inverse of the sum of the *lengths* of shortest paths from each node to every other node. That means that to compute it, we first need to calculate the **geodesic distance matrix** ($\\mathbf{G}$). This is matrix in which each entry $g_{ij}$ records the *length* of the shortest path(s) between row node $i$ and column node $j$. Then, we sum the rows (or columns) of this symmetric matrix and then we obtain the inverse to get the closeness of each node:\n\n$$\nC^{CLO}_i = \\left[\\sum_{j \\neq i}^N g_{ij}\\right]^{-1}\n$$\n\nLet's see how this works. We first load our trusty *Pulp Fiction* data set from the `networkdata` package, which is an **undirected** graph of character scene co-appearances in the film:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    library(networkdata)\n    library(igraph)\n    library(stringr) #using stringr to change names from all caps to title case\n    g <- movie_559\n    V(g)$name <- str_to_title(V(g)$name)\n    V(g)$name[which(V(g)$name == \"Esmarelda\")] <- \"Esmeralda\" #fixing misspelled name\n    E(g)$weight <- 1 #setting edge weights to 1.0\n```\n:::\n\n\nLet us extract the geodesic distance matrix of the graph using the `distances` function in `igraph`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   G <- distances(g) #geodesic distance matrix\n   G[1:10, 1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Brett Buddy Butch Capt Koons Ed Sullivan English Dave Esmeralda\nBrett            0     2     1          2           2            2         2\nBuddy            2     0     2          2           2            2         3\nButch            1     2     0          1           2            1         1\nCapt Koons       2     2     1          0           2            2         2\nEd Sullivan      2     2     2          2           0            2         3\nEnglish Dave     2     2     1          2           2            0         2\nEsmeralda        2     3     1          2           3            2         0\nFabienne         1     3     1          2           3            2         2\nFourth Man       2     2     2          2           2            2         3\nGawker #2        2     3     1          2           3            2         2\n             Fabienne Fourth Man Gawker #2\nBrett               1          2         2\nBuddy               3          2         3\nButch               1          2         1\nCapt Koons          2          2         2\nEd Sullivan         3          2         3\nEnglish Dave        2          2         2\nEsmeralda           2          3         2\nFabienne            0          2         2\nFourth Man          2          0         3\nGawker #2           2          3         0\n```\n:::\n:::\n\n\nThen we compute the closeness of each node like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   close1 <- rowSums(G)^-1 #inverse of the row sums of G\n   round(close1, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Brett           Buddy           Butch      Capt Koons     Ed Sullivan \n         0.0137          0.0115          0.0167          0.0133          0.0115 \n   English Dave       Esmeralda        Fabienne      Fourth Man       Gawker #2 \n         0.0132          0.0104          0.0122          0.0116          0.0106 \n    Honey Bunny          Jimmie            Jody           Jules           Lance \n         0.0130          0.0118          0.0118          0.0164          0.0118 \n        Manager       Marsellus          Marvin         Maynard             Mia \n         0.0125          0.0143          0.0135          0.0109          0.0145 \n         Mother          Patron      Pedestrian        Preacher         Pumpkin \n         0.0133          0.0125          0.0106          0.0116          0.0130 \n         Raquel           Roger Sportscaster #1 Sportscaster #2        The Gimp \n         0.0118          0.0135          0.0106          0.0077          0.0079 \n       The Wolf         Vincent        Waitress         Winston           Woman \n         0.0118          0.0192          0.0091          0.0118          0.0133 \n      Young Man     Young Woman             Zed \n         0.0091          0.0091          0.0079 \n```\n:::\n:::\n\n\nOf course, we could have just used the available function in `igraph` and computed the closeness centrality directly from the graph object using the function `closeness`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   close2 <- closeness(g)\n   round(close2, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Brett           Buddy           Butch      Capt Koons     Ed Sullivan \n         0.0137          0.0115          0.0167          0.0133          0.0115 \n   English Dave       Esmeralda        Fabienne      Fourth Man       Gawker #2 \n         0.0132          0.0104          0.0122          0.0116          0.0106 \n    Honey Bunny          Jimmie            Jody           Jules           Lance \n         0.0130          0.0118          0.0118          0.0164          0.0118 \n        Manager       Marsellus          Marvin         Maynard             Mia \n         0.0125          0.0143          0.0135          0.0109          0.0145 \n         Mother          Patron      Pedestrian        Preacher         Pumpkin \n         0.0133          0.0125          0.0106          0.0116          0.0130 \n         Raquel           Roger Sportscaster #1 Sportscaster #2        The Gimp \n         0.0118          0.0135          0.0106          0.0077          0.0079 \n       The Wolf         Vincent        Waitress         Winston           Woman \n         0.0118          0.0192          0.0091          0.0118          0.0133 \n      Young Man     Young Woman             Zed \n         0.0091          0.0091          0.0079 \n```\n:::\n:::\n\n\nOnce we have the closeness centrality values, we are naturally interested in who are the top nodes. The following code creates a table listing the top ten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(kableExtra)\n   close2 <- sort(close2, decreasing = TRUE)\n   close2 <- data.frame(close2[1:10])\n   kbl(close2, format = \"pipe\", align = c(\"l\", \"c\"),\n       col.names = c(\"Character\", \"Closeness\"), digits = 4,\n       caption = \"Top Ten Closeness Characters in Pulp Fiction Network.\") %>% \n   kable_styling(bootstrap_options = c(\"hover\", \"condensed\", \"responsive\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-hover table-condensed table-responsive\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Top Ten Closeness Characters in Pulp Fiction Network.</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Character </th>\n   <th style=\"text-align:left;\"> Closeness </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Vincent </td>\n   <td style=\"text-align:left;\"> 0.0192 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Butch </td>\n   <td style=\"text-align:left;\"> 0.0167 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Jules </td>\n   <td style=\"text-align:left;\"> 0.0164 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mia </td>\n   <td style=\"text-align:left;\"> 0.0145 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Marsellus </td>\n   <td style=\"text-align:left;\"> 0.0143 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Brett </td>\n   <td style=\"text-align:left;\"> 0.0137 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Marvin </td>\n   <td style=\"text-align:left;\"> 0.0135 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Roger </td>\n   <td style=\"text-align:left;\"> 0.0135 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Capt Koons </td>\n   <td style=\"text-align:left;\"> 0.0133 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mother </td>\n   <td style=\"text-align:left;\"> 0.0133 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nIt makes sense that the three main characters are also the ones that are at closest distances from everyone else!\n\n## Normalized Closeness\n\nWe can also compute the **normalized closeness centrality** which is given by:\n\n$$\nC^{NCLO}_i = \\left[\\frac{\\sum_{j \\neq i}^N g_{ij}}{N-1}\\right]^{-1} = \\frac{N-1}{\\sum_{j \\neq i}g_{ij}}\n$$\n\nWhere $N$ is the number of nodes in the network. The normalized closeness is just the inverse of the *average* distance of node $i$ to the other nodes in the network (e.g., the inverse of the sum of the rows of $\\mathbf{G}$ divided by $N-1$).\n\nIn `R` this is just:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   close3 <- (vcount(g) - 1)/(rowSums(G))\n   round(close3, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Brett           Buddy           Butch      Capt Koons     Ed Sullivan \n         0.5068          0.4253          0.6167          0.4933          0.4253 \n   English Dave       Esmeralda        Fabienne      Fourth Man       Gawker #2 \n         0.4868          0.3854          0.4512          0.4302          0.3936 \n    Honey Bunny          Jimmie            Jody           Jules           Lance \n         0.4805          0.4353          0.4353          0.6066          0.4353 \n        Manager       Marsellus          Marvin         Maynard             Mia \n         0.4625          0.5286          0.5000          0.4022          0.5362 \n         Mother          Patron      Pedestrian        Preacher         Pumpkin \n         0.4933          0.4625          0.3936          0.4302          0.4805 \n         Raquel           Roger Sportscaster #1 Sportscaster #2        The Gimp \n         0.4353          0.5000          0.3936          0.2846          0.2913 \n       The Wolf         Vincent        Waitress         Winston           Woman \n         0.4353          0.7115          0.3364          0.4353          0.4933 \n      Young Man     Young Woman             Zed \n         0.3364          0.3364          0.2913 \n```\n:::\n:::\n\n\nWhich gives us the same result as using the `igraph` function with the argument `normalized` set to `TRUE`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   close3 <- closeness(g, normalized = TRUE)\n   round(close3, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Brett           Buddy           Butch      Capt Koons     Ed Sullivan \n         0.5068          0.4253          0.6167          0.4933          0.4253 \n   English Dave       Esmeralda        Fabienne      Fourth Man       Gawker #2 \n         0.4868          0.3854          0.4512          0.4302          0.3936 \n    Honey Bunny          Jimmie            Jody           Jules           Lance \n         0.4805          0.4353          0.4353          0.6066          0.4353 \n        Manager       Marsellus          Marvin         Maynard             Mia \n         0.4625          0.5286          0.5000          0.4022          0.5362 \n         Mother          Patron      Pedestrian        Preacher         Pumpkin \n         0.4933          0.4625          0.3936          0.4302          0.4805 \n         Raquel           Roger Sportscaster #1 Sportscaster #2        The Gimp \n         0.4353          0.5000          0.3936          0.2846          0.2913 \n       The Wolf         Vincent        Waitress         Winston           Woman \n         0.4353          0.7115          0.3364          0.4353          0.4933 \n      Young Man     Young Woman             Zed \n         0.3364          0.3364          0.2913 \n```\n:::\n:::\n\n\n## Computing the Geodesic Distance Matrix\n\nAs noted by @fouss_etal16 [p. 56, Algorithm 1.2] the geodesic distance matrix returned by the `distances` function in `igraph` can be computed by a relatively simple algorithm, a version of which goes like this.\n\nFirst we define a \"cost matrix\" $\\mathbf{C}$ with entries $c_{ij} = 1$ if nodes $i$ and $j$ are adjacent in the graph and $g_{ij} = \\infty$ if they are not (if $i = j$ then $c_{ij} = 0$):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   C <- 1/as.matrix(as_adjacency_matrix((g))) #cost matrix\n   diag(C) <- 0\n   C[1:10, 1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Brett Buddy Butch Capt Koons Ed Sullivan English Dave Esmeralda\nBrett            0   Inf     1        Inf         Inf          Inf       Inf\nBuddy          Inf     0   Inf        Inf         Inf          Inf       Inf\nButch            1   Inf     0          1         Inf            1         1\nCapt Koons     Inf   Inf     1          0         Inf          Inf       Inf\nEd Sullivan    Inf   Inf   Inf        Inf           0          Inf       Inf\nEnglish Dave   Inf   Inf     1        Inf         Inf            0       Inf\nEsmeralda      Inf   Inf     1        Inf         Inf          Inf         0\nFabienne         1   Inf     1        Inf         Inf          Inf       Inf\nFourth Man     Inf   Inf   Inf        Inf         Inf          Inf       Inf\nGawker #2      Inf   Inf     1        Inf         Inf          Inf       Inf\n             Fabienne Fourth Man Gawker #2\nBrett               1        Inf       Inf\nBuddy             Inf        Inf       Inf\nButch               1        Inf         1\nCapt Koons        Inf        Inf       Inf\nEd Sullivan       Inf        Inf       Inf\nEnglish Dave      Inf        Inf       Inf\nEsmeralda         Inf        Inf       Inf\nFabienne            0        Inf       Inf\nFourth Man        Inf          0       Inf\nGawker #2         Inf        Inf         0\n```\n:::\n:::\n\n\nNow, we loop through each node pair in the graph $i$, $j$, substituting the entries in the $\\mathbf{C}$ matrix with the following expression at each iteration $k$:\n\n$$\nc^{(k)}_{ij} = min\\left[c^{(k-1)}_{ij}, \\left(c^{(k-1)}_{ik} + c^{(k-1)}_{kj}\\right)\\right]\n$$\n\nWe stop once none of the entries in $\\mathbf{C}$ are equal to `Inf` (in the case of a connected undirected graph).\n\nHere's a little `R` program that implements this idea:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   n <- nrow(C)\n   while (sum(C[upper.tri(C)]) == Inf) {\n      for(i in 1:n) {\n         for (j in i:n) { #looping through upper triangle\n            for (k in 1:n) {\n               if (i != k & j != k & i != j) {C[i,j] <- min(C[i,j], (C[i, k] + C[k, j]))}\n               }\n            }\n         }\n      }\n   C[lower.tri(C)] <- t(C)[lower.tri(C)] #copying upper triangle into lower triangle\n```\n:::\n\n\nAnd as we can see the entries in `C` are the same as those returned by `distances` earlier:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   C[1:10, 1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Brett Buddy Butch Capt Koons Ed Sullivan English Dave Esmeralda\nBrett            0     2     1          2           2            2         2\nBuddy            2     0     2          2           2            2         3\nButch            1     2     0          1           2            1         1\nCapt Koons       2     2     1          0           2            2         2\nEd Sullivan      2     2     2          2           0            2         4\nEnglish Dave     2     2     1          2           2            0         2\nEsmeralda        2     3     1          2           4            2         0\nFabienne         1     3     1          2           3            2         2\nFourth Man       2     2     2          2           2            2         3\nGawker #2        2     3     1          2           3            2         2\n             Fabienne Fourth Man Gawker #2\nBrett               1          2         2\nBuddy               3          2         3\nButch               1          2         1\nCapt Koons          2          2         2\nEd Sullivan         3          2         3\nEnglish Dave        2          2         2\nEsmeralda           2          3         2\nFabienne            0          2         2\nFourth Man          2          0         3\nGawker #2           2          3         0\n```\n:::\n:::\n\n\n## Markov Closeness\n\nWe can use some of the random walk concepts discussed [here](random-walk.qmd) to construct a variant of the closeness centrality. The trick is that instead of using the length of the shortest path between each pair of nodes are our measure of \"farness\" (which we invert to produce closeness), we use the **average first passage time** between them, which is also a measure of farness, but it is based on random walks on *all* paths in the graph regardless of length. That is, two nodes $i$ and $j$ are far in the graph if it takes a long time for a random walker starting at $i$ to get to $j$ (on average).\n\nSo all we need to do is recycle the code we used before to compute the average first passage time to get our farness matrix $\\mathbf{M}$. Here it is packaged as a function that takes the graph as input:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   avg.first.pass <- function(w) {\n      x <- as.matrix(as_adjacency_matrix(w))\n      e <- matrix(1, nrow(x), 1) #column vector of all ones\n      d <- degree(w) #degree vector \n      h <- matrix(1/nrow(x), nrow(x), nrow(x))\n      l <- solve((diag(d) - x) + h) - h\n      z <- sum(d) * (e %*% t(diag(l))) - (sum(d) * l) + (l %*% d) %*% t(e) - (e %*% (t(d) %*% l))\n      rownames(z) <- V(w)$name\n      colnames(z) <- V(w)$name\n      return(z)\n   }\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n   M <- avg.first.pass(g)\n   round(M, 1)[1:10, 1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Brett Buddy Butch Capt Koons Ed Sullivan English Dave Esmeralda\nBrett          0.0 110.8  13.1       49.1       110.8         53.9     216.1\nBuddy         35.0   0.0  16.7       44.4       102.0         51.6     219.7\nButch         30.6 110.0   0.0       44.2       110.0         50.6     203.0\nCapt Koons    34.5 105.7  12.2        0.0       105.7         52.3     215.2\nEd Sullivan   35.0 102.0  16.7       44.4         0.0         51.6     219.7\nEnglish Dave  32.8 106.4  12.0       45.7       106.4          0.0     215.0\nEsmeralda     31.6 111.0   1.0       45.2       111.0         51.6       0.0\nFabienne      21.6 111.8  11.1       49.1       111.8         54.6     214.1\nFourth Man    33.2 109.2  18.2       49.7       109.2         55.8     221.2\nGawker #2     31.1 111.2   7.8       47.6       111.2         50.9     210.8\n             Fabienne Fourth Man Gawker #2\nBrett            62.2      106.1      83.0\nBuddy            76.6      106.3      87.3\nButch            69.2      108.5      77.2\nCapt Koons       75.1      108.0      84.9\nEd Sullivan      76.6      106.3      87.3\nEnglish Dave     74.2      107.6      81.7\nEsmeralda        70.2      109.5      78.2\nFabienne          0.0      105.7      83.5\nFourth Man       73.4        0.0      88.4\nGawker #2        72.2      109.4       0.0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n   m.closeness <- (vcount(g) - 1) * rowSums(M)^-1\n   sort(m.closeness, decreasing = TRUE)[1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       The Gimp             Zed Sportscaster #2         Maynard Sportscaster #1 \n     0.01173965      0.01173965      0.01168773      0.01128148      0.01110540 \n      Esmeralda       Gawker #2      Pedestrian           Buddy     Ed Sullivan \n     0.01069453      0.01027273      0.01027273      0.01026157      0.01026157 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n   rowSums(M)^-1 * (vcount(g) - 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Brett           Buddy           Butch      Capt Koons     Ed Sullivan \n     0.01008473      0.01026157      0.01020489      0.01013598      0.01026157 \n   English Dave       Esmeralda        Fabienne      Fourth Man       Gawker #2 \n     0.01015026      0.01069453      0.01019696      0.01023256      0.01027273 \n    Honey Bunny          Jimmie            Jody           Jules           Lance \n     0.01004095      0.01017907      0.01017643      0.01005170      0.01017643 \n        Manager       Marsellus          Marvin         Maynard             Mia \n     0.01005733      0.01008772      0.01008379      0.01128148      0.01010784 \n         Mother          Patron      Pedestrian        Preacher         Pumpkin \n     0.01013598      0.01005733      0.01027273      0.01022047      0.01004095 \n         Raquel           Roger Sportscaster #1 Sportscaster #2        The Gimp \n     0.01017907      0.01008379      0.01110540      0.01168773      0.01173965 \n       The Wolf         Vincent        Waitress         Winston           Woman \n     0.01017907      0.01005749      0.01011230      0.01017907      0.01013598 \n      Young Man     Young Woman             Zed \n     0.01011230      0.01011230      0.01173965 \n```\n:::\n:::\n\n\n## Closeness Centrality in Directed Graphs\nWhat about closeness centrality for a directed network? Let us see how this works using a **subgraph** of the @lazega01 `law_advice` network, this time selecting just women under the age of forty:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    g <- law_advice\n    women <- which(V(g)$gender == 2) #selecting women\n    wg <- subgraph(g, women)\n    young <- which(V(wg)$age < 40) #selecting women under forty\n    wg <- subgraph(wg, young)\n    V(wg)$name <- 1:vcount(wg) #naming nodes\n```\n:::\n\n\nThis network is small enough that a plot could be informative about its structure. Let us plot it using the package `ggraph`, a visualization package that follows the same principles as the `ggplot` grammar of graphics but for network graphs (see [here](https://exts.ggplot2.tidyverse.org/ggraph.html)).\n\n\n::: {.cell fig-cap-location='margin'}\n\n```{.r .cell-code}\n   #install.packages(\"ggraph\")\n   library(ggraph)\n    p <- ggraph(wg, layout = 'auto')\n    p <- p + geom_edge_parallel(color = \"steelblue\", edge_width = 0.5,\n                                arrow = arrow(length = unit(2.5, 'mm')),\n                                end_cap = circle(4, 'mm'), \n                                sep = unit(3, 'mm'))\n    p <- p + geom_node_point(aes(x = x, y = y), size = 8, color = \"tan2\") \n    p <- p + geom_node_text(aes(label = 1:vcount(wg)), size = 4, color = \"white\")\n    p <- p + theme_graph() \n    p\n```\n\n::: {.cell-output-display}\n![Women lawyers advice network](closcent_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nNow a question we might ask is who has the greatest closeness centrality in this advice network. We could proceed as usual and compute the geodesic distances between actors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   G <- distances(wg)\n   G\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   1 2 3 4 5 6 7 8 9 10 11 12\n1  0 1 2 1 3 3 4 2 2  3  3  3\n2  1 0 2 1 2 3 3 1 1  3  3  3\n3  2 2 0 1 1 1 2 2 3  1  1  1\n4  1 1 1 0 2 2 3 2 2  2  2  2\n5  3 2 1 2 0 1 1 1 2  2  2  2\n6  3 3 1 2 1 0 2 2 3  1  2  1\n7  4 3 2 3 1 2 0 2 3  3  3  3\n8  2 1 2 2 1 2 2 0 1  3  3  3\n9  2 1 3 2 2 3 3 1 0  4  4  4\n10 3 3 1 2 2 1 3 3 4  0  1  1\n11 3 3 1 2 2 2 3 3 4  1  0  1\n12 3 3 1 2 2 1 3 3 4  1  1  0\n```\n:::\n:::\n\n\nNote that this is not quite right. In `igraph` the default settings of the distance function treats the graph as undirected even though it is actually directed. So it doesn't use the strict **directed paths**, but it just treats them all as **semi-paths** ignoring direction. That is why, for instance, it counts node 1 as being \"adjacent\" to node 4 even though there is only one incoming link from 4 to 1 and why the whole matrix is symmetric, when we know from just eyeballing the network that there is a lot of asymmetry in terms of who can reach who via directed paths. \n\nTo get the actual directed distance matrix, we need to specify the \"mode\" option, asking whether we want in or out paths. Here, we follow convention and select the out-paths:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   G <- distances(wg, mode = \"out\")\n   G\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   1 2   3   4   5   6   7   8   9  10  11  12\n1  0 1 Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf\n2  1 0 Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf\n3  2 2   0   1 Inf   1 Inf Inf Inf Inf Inf Inf\n4  1 1   1   0 Inf   2 Inf Inf Inf Inf Inf Inf\n5  3 2   1   2   0   1   1   1   2 Inf Inf Inf\n6  3 3   1   2 Inf   0 Inf Inf Inf Inf Inf Inf\n7  4 3   2   3   1   2   0   2   3 Inf Inf Inf\n8  2 1 Inf Inf Inf Inf Inf   0   1 Inf Inf Inf\n9  2 1 Inf Inf Inf Inf Inf   1   0 Inf Inf Inf\n10 3 3   1   2 Inf   1 Inf Inf Inf   0   1   2\n11 3 3   1   2 Inf   2 Inf Inf Inf   1   0   1\n12 3 3   1   2 Inf   1 Inf Inf Inf   1   1   0\n```\n:::\n:::\n\n\nThis is better but introduces a problem. The directed graph is not **strongly connected**, so it means that some nodes cannot reach other ones via a directed path of *any* length. That means that the **geodesic distances** from a node to an unreachable node is coded as \"infinite\" (`Inf`). The problem with infinity is that it gets in the way of calculating sums of distances, a requirement for the closeness centrality. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n   G <- distances(wg, mode = \"out\")\n   rowSums(G)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  1   2   3   4   5   6   7   8   9  10  11  12 \nInf Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf Inf \n```\n:::\n:::\n\n\nAdding infinity to a number just returns infinity so all the rows with at least one `Inf` in the distance matrix get an `Inf` for the row sum. In this case that's all of them. A bummer.\n\n### Harmonic Centrality\nBut dont' worry there's a patch. It is called the **harmonic centrality** [@rochat09].^[@agneessens_etal17 call the harmonic centrality \"reciprocal closeness\"] This is a variation on the closeness centrality that works whether you are working with connected or disconnected graphs (or in the case of directed graphs regardless of whether the graph is strongly or weakly connected), and therefore regardless of whether the geodesic distance matrix contains `Inf`s.^[Some people [@boldi_vigna14] claim that the harmonic centrality is the *only* centrality measure that could be called by that name from a purely axiomatic mathematical approach, but that's a different story.]  \n\nThe main difference between the harmonic and regular closeness centrality is that instead of calculating the inverse of the sum of the distances for each node, we calculate the *sum of the inverses*:\n\n$$\nC^{HC}_i = \\sum_{j \\neq i}(g_{ij})^{-1}\n$$\n\nAnd the normalized version:\n\n$$\nC^{NHC}_i = \\frac{\\sum_{j \\neq i}(g_{ij})^{-1}}{N-1}\n$$\n\nIn `R` we can do this as follows. First, let's compute the inverse of the entries of the geodesic distance matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   inv.G = G^-1\n   diag(inv.G) <- 0 #setting diagonals to zero\n   round(inv.G, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1     2   3     4 5   6 7   8     9 10 11  12\n1  0.000 1.000 0.0 0.000 0 0.0 0 0.0 0.000  0  0 0.0\n2  1.000 0.000 0.0 0.000 0 0.0 0 0.0 0.000  0  0 0.0\n3  0.500 0.500 0.0 1.000 0 1.0 0 0.0 0.000  0  0 0.0\n4  1.000 1.000 1.0 0.000 0 0.5 0 0.0 0.000  0  0 0.0\n5  0.333 0.500 1.0 0.500 0 1.0 1 1.0 0.500  0  0 0.0\n6  0.333 0.333 1.0 0.500 0 0.0 0 0.0 0.000  0  0 0.0\n7  0.250 0.333 0.5 0.333 1 0.5 0 0.5 0.333  0  0 0.0\n8  0.500 1.000 0.0 0.000 0 0.0 0 0.0 1.000  0  0 0.0\n9  0.500 1.000 0.0 0.000 0 0.0 0 1.0 0.000  0  0 0.0\n10 0.333 0.333 1.0 0.500 0 1.0 0 0.0 0.000  0  1 0.5\n11 0.333 0.333 1.0 0.500 0 0.5 0 0.0 0.000  1  0 1.0\n12 0.333 0.333 1.0 0.500 0 1.0 0 0.0 0.000  1  1 0.0\n```\n:::\n:::\n\n\nNote that in this matrix of inverse distances, the closest (adjacent) nodes get the maximum score of one, and nodes farther apart when smaller scores (approaching zero). More importantly, those pesky `Inf`s disappear (!) because unreachable directed pairs of nodes get the lowest score, corresponding to $1/\\infty = 0$. Turns out the mathematics of infinity weren't our enemy after all. \n\nAlso note that the reachability relation expressed in this matrix is asymmetric: So node 4 can reach node 1 (there is a directed tie from 4 to 1), but node 1 cannot reach 4. This is precisely what we want. \n\nOnce we have this matrix of inverse distances, we can then we can compute the normalized harmonic centrality the same way as regular closeness by adding up the row scores for each node and dividing by the number of nodes minus one:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   close4 <- rowSums(inv.G)/(vcount(wg) - 1)\n   round(close4, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     1      2      3      4      5      6      7      8      9     10     11 \n0.0909 0.0909 0.2727 0.3182 0.5303 0.1970 0.3409 0.2273 0.2273 0.4242 0.4242 \n    12 \n0.4697 \n```\n:::\n:::\n\n\nWe can see that the highest harmonic closeness centrality node is 5, followed by 12. Here's a plot of the network highlighting the highest harmonic centrality node. \n\n\n::: {.cell fig-cap-location='margin'}\n\n```{.r .cell-code}\n   col <- rep(\"tan2\", vcount(wg)) #creating node color vector\n   col[which(close4 == max(close4))] <- \"red\" #changing color of max centrality node to red\n   p <- p + geom_node_point(aes(x = x, y = y), size = 8, color = col)\n   p <- p + geom_node_text(aes(label = 1:vcount(wg)), size = 4, color = \"white\")\n   p\n```\n\n::: {.cell-output-display}\n![Women lawyers advice network with highest closeness centrality node in red](closcent_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nOf course, `igraph` has a built in function to calculate the harmonic centrality called (you guessed it) `harmonic_centrality`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   close4 <- harmonic_centrality(wg, normalized = TRUE)\n   round(close4, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     1      2      3      4      5      6      7      8      9     10     11 \n0.0909 0.0909 0.2727 0.3182 0.5303 0.1970 0.3409 0.2273 0.2273 0.4242 0.4242 \n    12 \n0.4697 \n```\n:::\n:::\n\n\nWhich gives us the same results (note we set the argument `normalized` to `TRUE` to get the normalized scores).\n\n## Generalized Harmonic Centrality\n\n@agneessens_etal17 propose a \"generalized\" version of the harmonic centrality that yields plain old degree centrality and the regular harmonic centrality as special cases. The key is to introduce a parameter $\\delta$ governing how much weight we give to shortest paths based on distance. Let's see how this works. \n\nRecall that (the normalized version of) the harmonic centrality we defined earlier is given by:\n\n$$\nC^{NHC}_i = \\frac{\\sum_{j \\neq i}(g_{ij})^{-1}}{N-1}\n$$\n\nFor any node $i$, where $g_{ij}$ is the geodesic distance between $i$ and every other node in the graph $j$, which could be \"infinite\" if there is no path linking them. \n\nAgneessens et al's tweak is to instead compute:\n\n$$\nC^{GHC}_i = \\frac{\\sum_{j \\neq i}(g_{ij})^{-\\delta}}{N-1}\n$$\n\nWhere $\\delta$ is a free parameter chosen by the researcher with the restriction that $\\delta \\geq 0$ (if you want to calculate a closeness measure as we will see below). \n\nWhen $\\delta = \\infty$ the numerator element $1/(g_{ij})^{\\infty} = 1$ only when nodes are adjacent and $g_{ij} = 1$ (because $1^{\\infty} = 1$); otherwise, for $g_{ij} > 1$ then $1/(g_{ij})^{\\infty} = 0$, and therefore the generalized harmonic centrality just becomes a (normalized) version of degree centrality. Alternatively, when $\\delta = 1$ we just get the plain old harmonic centrality we defined earlier.\n\nThe interesting cases come from $1 > \\delta < \\infty$ and $0 > \\delta < 1$. In the first case, nodes at shorter distances are weighted more (like in the standard harmonic centrality measure) as $\\delta$ becomes bigger and bigger then the generalized harmonic centrality approximates degree. For values below one, as $\\delta$ approaches zero, then indirect connections to nodes of greater length are discounted less, and thus count for \"more\" in defining your generalized harmonic centrality score.\n\nLet us see a real-world example of the generalized harmonic centrality in action:\n\nFirst, we create a custom function to compute the generalized harmonic centrality:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   g.harm <- function(x, d) {\n      library(igraph)\n      w <- distances(x) #get distances from graph object\n      w <- (w^d)^-1 #matrix of generalized inverse distances\n      diag(w) <- 0 #set diagonals to zero\n      h <- rowSums(w)/(vcount(x) - 1) #summing and averaging\n      return(h)\n      }\n```\n:::\n\n\nSecond, we compute three versions of the harmonic centrality, with $\\delta = 5$, $\\delta = 0.05$, and $\\delta = -5$, using the full (unrestricted by age) subgraph of the `law_advice` network composed of the women lawyers at the firm, with relations constrained to be undirected:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   women <- which(V(law_advice)$gender == 2)\n   wg <- subgraph(law_advice, women)\n   wg <- as.undirected(wg)\n   close5 <- g.harm(wg, d = 5)\n   close6 <- g.harm(wg, d = 0.05)\n   far1 <- g.harm(wg, d = -5)\n```\n:::\n\n\n- The first version of the harmonic centrality in line 5, with a positive value of $\\delta$ above zero, will compute centrality scores emphasizing *direct* (one-step) connections, thus coming closer to **degree**. \n\n- The second version, in line 6, with a value of $\\delta$ close to zero, will give comparatively more emphasis to *indirect* connections weighing longer paths almost as much as shorter paths (but always a little less), thus being more similar to **closeness** centrality. \n\n- Finally, the last version, in line 7, with $\\delta < 0$, will weigh *longer* paths more than shorter ones, serving as a measure of **eccentricity** (farness from others) not closeness. \n\n\n\n::: {.cell fig-cap-location='margin'}\n::: {.cell-output-display}\n![Full women lawyers advice network](closcent_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nAbove is a plot of the women lawyers network showing the top node for each of the centralities:\n\n- In red we have node 3 who has the largest degree ($k(3) = 8$) and thus comes out on top using the generalized harmonic centrality version emphasizing direct connections ($\\delta > 1$). \n\n- Then in blue we have node 9 who can reach the most others via the shortest paths, and thus comes out on top when the generalized harmonic centrality emphasizes indirect connectivity. \n\n- Finally, in purple we have node 12, which is *farthest* from everyone else, and thus comes out on \"top\" when longer indirect connections count for more ($\\delta < 0)$. \n\nAs we said earlier, both regular harmonic centrality and degree are special cases of the generalized measure. We can check this by setting $\\delta$ to either one or infinity.\n\nWhen we set $\\delta=1$ the generalized harmonic centrality is the same as the normalized harmonic centrality:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(g.harm(wg, d = 1), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.598 0.534 0.706 0.598 0.657 0.627 0.426 0.539 0.696 0.647 0.667 0.407\n[13] 0.588 0.520 0.583 0.603 0.559 0.544\n```\n:::\n\n```{.r .cell-code}\n   round(harmonic_centrality(wg, normalized = TRUE), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.598 0.534 0.706 0.598 0.657 0.627 0.426 0.539 0.696 0.647 0.667 0.407\n[13] 0.588 0.520 0.583 0.603 0.559 0.544\n```\n:::\n:::\n\n\nWhen we set $\\delta=\\infty$ the generalized harmonic centrality is the same as the normalized degree centrality:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(g.harm(wg, d = Inf), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.235 0.176 0.471 0.235 0.353 0.294 0.059 0.176 0.412 0.353 0.412 0.059\n[13] 0.235 0.176 0.235 0.353 0.235 0.235\n```\n:::\n\n```{.r .cell-code}\n   round(degree(wg, normalized = TRUE), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.235 0.176 0.471 0.235 0.353 0.294 0.059 0.176 0.412 0.353 0.412 0.059\n[13] 0.235 0.176 0.235 0.353 0.235 0.235\n```\n:::\n:::\n",
    "supporting": [
      "closcent_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}