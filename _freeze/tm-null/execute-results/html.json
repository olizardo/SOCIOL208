{
  "hash": "6d80e3c08eb4b2d240ed0ead0416d7d0",
  "result": {
    "markdown": "---\ntitle: \"Graph Ensembles in Two-Mode Networks\"\nexecute: \n  eval: true\n  echo: true\n  output: true\n  warning: false\n  message: false\nformat: \n   html:\n      code-line-numbers: true\n---\n\n\nAs we saw in the [graph ensemble lesson](swap.qmd), there are many approaches to randomizing the structure of one-mode networks when the aim is to create **graph ensembles** preserving selected properties. These ensembles, in turn, can be used to do **null hypothesis testing** in networks. \n\nNot surprisingly, a similar suite of techniques exist for the two-mode case, but until recently various approaches were scattered (and reduplicated) across a bunch of literatures in social network analysis, ecology, network physics, and  computer science [@neal_etal24]. \n\n## Two-Mode Erdos-Renyi Model\n\nLike with one-mode networks, the simplest null model for two-mode networks is one that preserves the number of nodes and the number of edges. This model, like we saw in the one-mode network case, also preserves anything that is a function of these two-quantities. In the two-mode case, this is the bipartite graph's **density** and the average degrees of the nodes in each mode (recall that two-mode networks [have two average degrees](two-mode.qmd)). This is thus a two-mode version of the **Erdos-Renyi** null model. \n\nLet's load up the *Southern Women* (SW) data and see how it works:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(igraph)\n   library(networkdata)\n   A <- as_biadjacency_matrix(southern_women)\n```\n:::\n\n\nLet's compute some [basic two-mode network statistics](two-mode.qmd):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   d <- sum(A)/(nrow(A)*ncol(A)) #density\n   ad.p <- mean(rowSums(A)) #average degree of people\n   ad.g <- mean(colSums(A)) #average degree of groups\n   d\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3531746\n```\n:::\n\n```{.r .cell-code}\n   ad.p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.944444\n```\n:::\n\n```{.r .cell-code}\n   ad.g\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.357143\n```\n:::\n:::\n\n\nWe can see that the density of the SW network is $d=$ 0.35, the average degree of people $\\bar{k_p}=$ 4.94 and the average degree of groups $\\bar{k_g}=$ 6.36.  \n\nNow, let's compute something on this network, like the **degree correlation** between people and groups, answering  the question: Do people with lots of memberships tend to join larger groups?\n\nWe already know the answer to this question for the SW data from the [two-mode network analysis lecture notes](two-mode.qmd), which is negative. In this network people with a lot of memberships connect to smaller groups. \n\nHere's a version of that function that takes the biadjacency matrix as input, creates the bipartite matrix from it and returns the two-mode degree correlation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   tm.deg.corr <- function(x) {\n      B <- rbind(\n                  cbind(matrix(0, nrow = nrow(x), ncol = nrow(x)), x),\n                  cbind(t(x), matrix(0, nrow = ncol(x), ncol = ncol(x)))\n                  ) #creating bipartite matrix\n      d <- data.frame(e = as.vector(B), \n                      rd = rep(rowSums(B), ncol(B)), \n                      cd = rep(colSums(B), each = nrow(B))\n                      )\n      return(cor(d[d$e == 1, ]$rd, d[d$e == 1, ]$cd))\n   }\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n   tm.deg.corr(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.3369979\n```\n:::\n:::\n\n\nWhich is the same number we got before. \n\nNow let's see how we can generate an Erdos-Renyi two-mode network with a specified number of edges. A simple approach goes like this: \n\nFirst, let's create a vectorized version of the adjacency matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   v.a <- as.vector(A)\n   v.a\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n [38] 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n [75] 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1\n[112] 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 0\n[149] 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0\n[186] 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n[223] 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n```\n:::\n:::\n\n\nThese are just the biadjacency matrix entries stretched out into a long vector of length equal to the number of rows multiplied by the number of columns of the matrix (18 $\\times$ 14 $=$ 252). \n\nThen we just reshuffle the values of this vector by reassigning vector positions across the entire length of the vector at random:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   v.shuff <- v.a[sample(1:length(v.a))]\n```\n:::\n\n\nNow we can just generate a new biadjacency matrix `A.perm` from the reshuffled vector `v.shuff`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   A.perm <- matrix(v.shuff, nrow = nrow(A)) #creating permuted biadjacency matrix\n   rownames(A.perm) <- rownames(A)\n   colnames(A.perm) <- colnames(A)\n   A.perm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          6/27 3/2 4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       0   0    1    0    0    1    0    0   0    0    0   1     0   0\nLAURA        0   0    0    0    0    1    1    1   1    0    0   0     0   0\nTHERESA      0   1    0    0    1    0    0    1   1    0    0   1     0   0\nBRENDA       0   1    0    1    0    0    0    0   0    1    1   0     0   1\nCHARLOTTE    0   0    0    0    0    1    1    0   1    1    0   1     1   1\nFRANCES      0   1    0    1    0    0    0    0   0    0    1   0     0   1\nELEANOR      0   0    1    1    1    0    1    0   0    0    1   1     1   1\nPEARL        0   1    0    0    1    0    0    0   0    0    1   0     0   0\nRUTH         1   0    0    0    1    0    1    0   0    0    0   1     0   0\nVERNE        0   0    0    1    0    0    0    0   0    0    0   0     0   0\nMYRNA        1   1    0    1    0    0    0    0   0    0    0   0     1   1\nKATHERINE    0   1    0    1    1    1    1    1   0    1    0   0     0   0\nSYLVIA       0   0    0    0    1    0    1    1   0    0    1   0     0   0\nNORA         0   0    1    0    1    0    1    0   1    0    0   0     0   0\nHELEN        1   1    1    0    0    1    0    0   0    0    1   1     1   1\nDOROTHY      0   1    0    0    1    1    1    0   1    0    0   0     0   0\nOLIVIA       0   1    1    0    0    1    1    0   0    0    1   1     0   1\nFLORA        1   0    1    0    0    0    0    1   1    0    0   0     1   0\n```\n:::\n:::\n\n\nWe can verify that `A.perm` has the same basic network statistics as `A`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   d <- sum(A.perm)/(nrow(A.perm)*ncol(A.perm)) #density\n   ad.p <- mean(rowSums(A.perm)) #average degree of people\n   ad.g <- mean(colSums(A.perm)) #average degree of groups\n   d\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3531746\n```\n:::\n\n```{.r .cell-code}\n   ad.p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4.944444\n```\n:::\n\n```{.r .cell-code}\n   ad.g\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.357143\n```\n:::\n:::\n\n\nBut *not* the same degree distributions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   rowSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         7         8         7         4         4         4         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         4         4         6         7         8         5         2 \n   OLIVIA     FLORA \n        2         2 \n```\n:::\n\n```{.r .cell-code}\n   rowSums(A.perm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        3         4         5         5         7         4         8         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         1         5         7         4         4         8         5 \n   OLIVIA     FLORA \n        7         5 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    3     3     6     4     8     8    10    14    12     5     4     6     3 \n  8/3 \n    3 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A.perm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    4     9     6     6     8     7     9     5     6     3     7     7     5 \n  8/3 \n    7 \n```\n:::\n:::\n\n\nWe can now package the two-mode permutation steps into a function called `tm.perm`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   tm.perm <- function(x) {\n      w <- matrix(as.vector(x)[sample(1:length(v.a))], nrow = nrow(x))\n      rownames(w) <- rownames(x)\n      colnames(w) <- colnames(x)\n      return(w)\n   }\n```\n:::\n\n\nAnd generate a 500 strong two-mode Erdos-Renyi graph ensemble for the SW data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   set.seed(4567)\n   G <- replicate(500, tm.perm(A), simplify = FALSE)\n```\n:::\n\n\nWe can now `sapply` the `tm.deg.corr` function from before across our ensemble to get 500 degree correlations:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   corrs <- sapply(G, tm.deg.corr)\n   corrs[1:100] #first hundred entries\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] -0.344356903 -0.134295344 -0.133596070 -0.267644558 -0.171674275\n  [6] -0.275663672 -0.283254133 -0.193806406 -0.337994690 -0.212437024\n [11] -0.257590223 -0.118158698 -0.242565641 -0.166337214 -0.173132238\n [16] -0.274868693 -0.217969624 -0.216451292 -0.291344341 -0.283195324\n [21] -0.207689408 -0.248837917 -0.198871612 -0.240695741 -0.221265615\n [26] -0.185705284 -0.289478802 -0.159541270 -0.171820823 -0.186560960\n [31] -0.215368270 -0.254480771 -0.177874085 -0.151141815 -0.289125269\n [36] -0.224790425 -0.201960650 -0.270071352 -0.116296228 -0.185726631\n [41] -0.303763988 -0.259510523 -0.218542183 -0.112107029 -0.243725759\n [46] -0.005737813 -0.198127012 -0.229914646 -0.204889016 -0.079508887\n [51]  0.027440505 -0.202949007 -0.218607373 -0.025492884 -0.133046441\n [56] -0.160869565 -0.185500601 -0.213562420 -0.155718555 -0.250021152\n [61] -0.053023663 -0.137790380 -0.236702431 -0.248327843 -0.131984233\n [66] -0.205270847 -0.198270225 -0.235000000 -0.286357283 -0.144811901\n [71] -0.294190720 -0.203126837 -0.116331339 -0.253407599 -0.191774271\n [76] -0.145264282 -0.202891718 -0.184967788 -0.141816921 -0.149469250\n [81] -0.218688180 -0.218279156 -0.012786560 -0.197629515 -0.148183895\n [86] -0.138678154 -0.277539621 -0.266943121 -0.304491726 -0.118560460\n [91] -0.129700324  0.004097715 -0.252852092 -0.239662227 -0.264175504\n [96] -0.219322074 -0.201478868 -0.206365547 -0.296350444 -0.136214570\n```\n:::\n:::\n\n\nSo let's see how our observed value stacks up in the grand scheme:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   library(ggplot2)\n   p <- ggplot(data = data.frame(round(corrs, 2)), aes(x = corrs))\n   p <- p + geom_histogram(binwidth = 0.015, stat = \"bin\", fill = \"darkblue\")\n   p <- p + geom_vline(xintercept = tm.deg.corr(A), \n                       color = \"red\", linetype = 1, linewidth = 1.5)\n   p <- p + geom_vline(xintercept = 0, linetype = 1, \n                       color = \"purple\", linewidth = 1.5)\n   p <- p + theme_minimal() + labs(x = \"Q by Level\", y = \"Freq.\")\n   p <- p + theme(axis.text = element_text(size = 12))\n   p <- p + annotate(\"text\", x=-0.04, y=45, label= \"Zero Point\", color = \"purple\")\n   p <- p + annotate(\"text\", x=-0.3, y=45, label= \"Obs. Value\", color = \"red\")\n   p\n```\n\n::: {.cell-output-display}\n![](tm-null_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nIt looks like our observed value is close to the tail end of the negative spectrum, suggesting it is statistically improbable to have been obvserved by chance. We can compute the value that corresponds to the 1st percentile of the assortativity distribution from the ensemble and then see if what observe is below that value ($p < 0.01$). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n   quantile(corrs, probs = 0.01)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1% \n-0.3587599 \n```\n:::\n\n```{.r .cell-code}\n   tm.deg.corr(A) < quantile(corrs, probs = 0.01)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   1% \nFALSE \n```\n:::\n:::\n\n\nWhoops. Looks like the observed value is not extreme enough using a $p <0.01$ criterion of statistical significance. Let's try a less stringent one:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        5% \n-0.3141873 \n```\n:::\n\n```{.r .cell-code}\n   tm.deg.corr(A) < quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  5% \nTRUE \n```\n:::\n:::\n\n\nAha! A test of the hypothesis that the observed value is smaller than the value at the 95th percentile of the distribution of values in this null graph ensemble returns a positive answer, suggesting that degree anti-correlation is present in the SW data, at statistically significant levels, net of density. \n\nAs before, if we wanted a more stringent **two-tailed test** we would need to create a vector with the *absolute value* of the two-mode degree correlation: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n   1 - ecdf(abs(corrs))(abs(tm.deg.corr(A)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.032\n```\n:::\n:::\n\n\nWhich is still statistically significant at conventional levels ($p <0.05$). \n\n## Fixed Degree Models\nAs we already noted, the two-mode Erdos-Renyi model fixes the number of edges (and thus the density and average degrees) in the network, but does not preserve the original degree distributions. We might want to test our hypotheses by using a two-mode graph ensemble that \"controls for\" the node degrees. \n\nHow do we do that? One complication is that we have two sets of degrees so we have more options than in the one mode case. We can fix the row (person) degree, or the column (group) degree or *both* degrees. \n\nLet's begin with the simplest case, in which we fix *either* the row or column degree but not both. \n\n### Fixing Row Degrees\n\nTo fix the row degrees, we need to randomize the entries in each row of the biadjacency matrix, while preserving the number of ones in that row. One way to do this is to write a function that takes an observed row of the matrix, randomizes it and then substitutes it for the observed row:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   rand.row <- function(r) {\n      return(r[sample(1:length(r))])\n      }\n```\n:::\n\n\nNow we can just `apply` the `rand.row` function to each row of the biadjacency matrix `A` to generate a new matrix `A.r`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   A.r <- apply(A, 1, rand.row)\n   A.r <- t(A.r)\n   rownames(A.r) <- rownames(A)\n   colnames(A.r) <- colnames(A)\n```\n:::\n\n\nHere's the original matrix `A`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   A\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          6/27 3/2 4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       1   1    1    1    1    1    0    1   1    0    0   0     0   0\nLAURA        1   1    1    0    1    1    1    1   0    0    0   0     0   0\nTHERESA      0   1    1    1    1    1    1    1   1    0    0   0     0   0\nBRENDA       1   0    1    1    1    1    1    1   0    0    0   0     0   0\nCHARLOTTE    0   0    1    1    1    0    1    0   0    0    0   0     0   0\nFRANCES      0   0    1    0    1    1    0    1   0    0    0   0     0   0\nELEANOR      0   0    0    0    1    1    1    1   0    0    0   0     0   0\nPEARL        0   0    0    0    0    1    0    1   1    0    0   0     0   0\nRUTH         0   0    0    0    1    0    1    1   1    0    0   0     0   0\nVERNE        0   0    0    0    0    0    1    1   1    0    0   1     0   0\nMYRNA        0   0    0    0    0    0    0    1   1    1    0   1     0   0\nKATHERINE    0   0    0    0    0    0    0    1   1    1    0   1     1   1\nSYLVIA       0   0    0    0    0    0    1    1   1    1    0   1     1   1\nNORA         0   0    0    0    0    1    1    0   1    1    1   1     1   1\nHELEN        0   0    0    0    0    0    1    1   0    1    1   1     0   0\nDOROTHY      0   0    0    0    0    0    0    1   1    0    0   0     0   0\nOLIVIA       0   0    0    0    0    0    0    0   1    0    1   0     0   0\nFLORA        0   0    0    0    0    0    0    0   1    0    1   0     0   0\n```\n:::\n:::\n\n\nAnd the reshuffled matrix `A.r`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   A.r\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          6/27 3/2 4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       1   0    0    1    0    1    1    1   1    0    1   0     0   1\nLAURA        0   0    1    1    1    0    0    0   1    0    1   1     0   1\nTHERESA      1   0    1    0    0    1    0    1   1    0    1   1     0   1\nBRENDA       0   1    1    0    1    0    1    0   0    1    0   0     1   1\nCHARLOTTE    0   0    1    0    0    0    0    0   1    1    1   0     0   0\nFRANCES      0   1    0    1    0    0    1    1   0    0    0   0     0   0\nELEANOR      0   0    0    0    0    0    1    0   0    1    1   0     0   1\nPEARL        0   0    0    0    1    0    0    0   1    1    0   0     0   0\nRUTH         0   0    0    0    0    1    0    1   0    1    0   0     0   1\nVERNE        0   0    0    0    1    1    0    1   0    0    0   0     1   0\nMYRNA        1   1    0    0    0    0    1    1   0    0    0   0     0   0\nKATHERINE    0   1    1    0    0    1    0    0   0    0    1   0     1   1\nSYLVIA       1   0    0    0    1    0    0    1   1    1    1   0     0   1\nNORA         1   1    0    1    1    1    0    1   0    1    0   0     1   0\nHELEN        0   0    1    0    1    1    0    0   0    1    0   0     0   1\nDOROTHY      1   0    0    0    0    0    0    0   0    1    0   0     0   0\nOLIVIA       0   1    0    0    0    0    0    0   0    1    0   0     0   0\nFLORA        0   0    0    0    0    0    0    0   0    0    0   1     0   1\n```\n:::\n:::\n\n\nNote that the new matrix `A.r` preserves the person degrees of the original:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   rowSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         7         8         7         4         4         4         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         4         4         6         7         8         5         2 \n   OLIVIA     FLORA \n        2         2 \n```\n:::\n\n```{.r .cell-code}\n   rowSums(A.r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         7         8         7         4         4         4         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         4         4         6         7         8         5         2 \n   OLIVIA     FLORA \n        2         2 \n```\n:::\n:::\n\n\nBut not the group degrees, because each person's memberships are randomly distributed across groups:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   colSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    3     3     6     4     8     8    10    14    12     5     4     6     3 \n  8/3 \n    3 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A.r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    6     6     6     4     7     7     5     8     6    10     7     3     4 \n  8/3 \n   10 \n```\n:::\n:::\n\n\nAll the other lower order statistics like density are preserved:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   sum(A.r)/(nrow(A.r)*ncol(A.r))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3531746\n```\n:::\n:::\n\n\nNow we package everything into a function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   fix.deg <- function(x, mode = 1) {\n      w <- apply(x, mode, function(r) {r[sample(1:length(r))]})\n      if (mode == 1) {\n         w <- t(w)\n         }\n      rownames(w) <- rownames(x)\n      colnames(w) <- colnames(x)\n      return(w)\n      }\n```\n:::\n\n\nWe then generate a graph ensemble of reshuffled matrices that preserve the person degrees, and compute our degree correlations in that set of networks:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   set.seed(4567)\n   G <- replicate(500, fix.deg(A), simplify = FALSE)\n   corrs <- sapply(G, tm.deg.corr)\n```\n:::\n\n\nLet's compute the degree correlations across this ensemble and see how our observed value stacks up in the grand scheme:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](tm-null_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nLooking pretty good! Let's check the p-value:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        5% \n-0.2756015 \n```\n:::\n\n```{.r .cell-code}\n   tm.deg.corr(A) < quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  5% \nTRUE \n```\n:::\n\n```{.r .cell-code}\n   1 - ecdf(abs(corrs))(abs(tm.deg.corr(A)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.016\n```\n:::\n:::\n\n\nNeat! Our result can continue to be defended at the $p < 0.05$ level. Still a chance of getting published.\n\n### Fixing Column Degrees\nWe can fix the column degrees using the same `fix.deg` function as earlier, but this time, we just change the `mode` argument to equal `2`, to `apply` the function to the columns and not the rows of the matrix `A`. \n\nFor instance:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   A.c <- fix.deg(A, mode = 2)\n   A.c\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          6/27 3/2 4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       0   1    0    1    1    1    1    0   1    0    1   1     0   0\nLAURA        0   0    1    0    0    0    1    1   1    0    0   0     0   0\nTHERESA      0   1    0    1    1    0    0    1   1    1    0   0     0   0\nBRENDA       0   0    1    0    0    1    0    1   0    0    1   1     1   0\nCHARLOTTE    0   0    0    0    0    1    0    1   1    0    0   0     0   0\nFRANCES      0   1    0    0    1    0    1    1   1    1    0   0     1   0\nELEANOR      0   0    0    0    0    0    1    0   0    1    1   0     0   0\nPEARL        0   0    0    0    0    0    0    0   1    1    0   0     0   0\nRUTH         0   0    0    0    1    0    0    1   1    0    0   0     0   0\nVERNE        1   0    1    0    1    1    1    1   1    0    0   1     0   1\nMYRNA        0   0    1    0    1    1    1    1   0    0    0   0     0   0\nKATHERINE    1   0    0    1    0    0    1    1   1    0    0   1     1   0\nSYLVIA       0   0    0    0    1    0    1    1   1    1    0   0     0   0\nNORA         1   0    1    0    1    0    1    1   0    0    0   0     0   0\nHELEN        0   0    0    0    0    1    0    1   1    0    0   1     0   1\nDOROTHY      0   0    0    0    0    1    0    0   0    0    1   0     0   0\nOLIVIA       0   0    0    0    0    1    1    1   1    0    0   0     0   0\nFLORA        0   0    1    1    0    0    0    1   0    0    0   1     0   1\n```\n:::\n:::\n\n\nWhich generates a reshuffled adjacency matrix that preserves the group degrees:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   colSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    3     3     6     4     8     8    10    14    12     5     4     6     3 \n  8/3 \n    3 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A.c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    3     3     6     4     8     8    10    14    12     5     4     6     3 \n  8/3 \n    3 \n```\n:::\n:::\n\n\nBut *not* the person degrees:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   rowSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         7         8         7         4         4         4         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         4         4         6         7         8         5         2 \n   OLIVIA     FLORA \n        2         2 \n```\n:::\n\n```{.r .cell-code}\n   rowSums(A.c)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         4         6         6         3         7         3         2 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        3         9         5         7         5         5         5         2 \n   OLIVIA     FLORA \n        4         5 \n```\n:::\n:::\n\n\nAnd now we test our hypothesis that there is degree anti-correlation in the SW data on an ensemble of graphs with fixed group degrees:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   set.seed(4567)\n   G <- replicate(500, fix.deg(A, mode = 2), simplify = FALSE)\n   corrs <- sapply(G, tm.deg.corr)\n```\n:::\n\n\nLet's see how things look:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](tm-null_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\nUh oh, adjusting for group degrees seems to have made our conclusions a bit more shaky. All of the estimated degree correlations are negative (below zero) and our observed value does not seem to be as extreme as before.   \n\nLet' see what the p-values say:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        5% \n-0.3316684 \n```\n:::\n\n```{.r .cell-code}\n   tm.deg.corr(A) < quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  5% \nTRUE \n```\n:::\n\n```{.r .cell-code}\n   1 - ecdf(abs(corrs))(abs(tm.deg.corr(A)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.036\n```\n:::\n:::\n\n\nStill significant at $p < 0.05$! \n\nRegardless, it is clear that our earlier conclusions from the Erdos-Renyi model were a bit too optimistic. What happens when we try to fix *both* the row and column degrees?\n\n### Fixing Row and Column Degrees\nTo fix row and column degrees, we play a swapping game. At each round, we select two random persons $a$ and $b$. Each person collects their memberships and calculates the memberships they have that the other person does not have (and vice versa). Thus, $a$ has a set of memberships that $b$ does not have, and $b$ has a set of memberships that $a$ does not have. Then they trade memberships $n$ times where $n$ is a number between zero and the minimum of the size of the two sets of memberships that the other person does not have. We repeat this trading game for $k$ number of times. \n\nBelow is a function called `make.swap` that implements this algorithm, called \"curveball\" [@neal_etal24]. The function takes the biadjacency matrix as input and repeats the swapping process described above 100 times:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   make.swap <- function(x, k = 100) {\n      z <- 1 #initializing counter\n      while(z <= k) {\n         n <- sample(rownames(x), 2) #sampling two people at random\n         a <- n[1] #person a\n         b <- n[2] #person b\n         a.m <- names(which(x[a, ] == 1)) #person a's memberships\n         b.m <- names(which(x[b, ] == 1)) #person b's memberships\n         ab <- setdiff(a.m, b.m) #memberships that a has that b does not\n         ba <- setdiff(b.m, a.m) #memberships that b has that a does not\n         w <- sample(0:min(length(ab), length(ba)), size = 1) #number of rounds of trade\n         if (w > 0) {\n            for (i in 1:w) {\n               ab.m <- sample(ab, 1) #membership that a will transfer to b\n               ba.m <- sample(ba, 1) #membership that b will transfer to a\n               x[a, ab.m] <- 0 #a loses membership\n               x[b, ab.m] <- 1 #b gains membership\n               x[b, ba.m] <- 0 #b loses membership\n               x[a, ba.m] <- 1 #a gains membership\n               a.m <- names(which(x[a, ] == 1)) #updating a's memberships\n               b.m <- names(which(x[b, ] == 1)) #updating b's memberships\n               ab <- setdiff(a.m, b.m) #updating differences between a and b's memberships\n               ba <- setdiff(b.m, a.m) #updating differences between b and a's memberships\n               }\n            }\n         z <- z + 1 #incrementing counter\n         }\n      return(x)\n   }\n```\n:::\n\n\nHere's an example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   A.s <- make.swap(A)\n   A.s\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          6/27 3/2 4/12 9/26 2/25 5/19 3/15 9/16 4/8 6/10 2/23 4/7 11/21 8/3\nEVELYN       0   0    1    0    0    0    1    1   1    0    1   1     1   1\nLAURA        0   1    1    0    1    1    0    1   1    0    0   1     0   0\nTHERESA      1   0    0    1    0    1    1    1   1    1    0   0     1   0\nBRENDA       0   0    1    0    0    1    1    1   1    1    1   0     0   0\nCHARLOTTE    0   1    0    0    0    0    1    1   0    0    0   0     0   1\nFRANCES      0   0    1    0    1    1    0    0   1    0    0   0     0   0\nELEANOR      0   0    0    0    1    0    1    1   1    0    0   0     0   0\nPEARL        0   0    0    0    0    0    1    0   1    0    0   1     0   0\nRUTH         0   0    0    1    1    0    1    1   0    0    0   0     0   0\nVERNE        1   0    0    0    0    0    0    1   0    0    0   1     0   1\nMYRNA        0   0    0    0    0    1    1    1   0    1    0   0     0   0\nKATHERINE    0   0    1    1    0    1    1    1   1    0    0   0     0   0\nSYLVIA       0   1    1    0    1    1    0    0   1    0    1   0     1   0\nNORA         1   0    0    1    1    0    1    1   1    1    0   1     0   0\nHELEN        0   0    0    0    1    0    0    1   1    1    0   1     0   0\nDOROTHY      0   0    0    0    1    0    0    0   1    0    0   0     0   0\nOLIVIA       0   0    0    0    0    0    0    1   0    0    1   0     0   0\nFLORA        0   0    0    0    0    1    0    1   0    0    0   0     0   0\n```\n:::\n:::\n\n\nWe can see that while the specifc entries of the swapped biadjacency matrix `A.s` are different from those of the original matrix `A` both the row and column degrees are preserved:\n \n\n::: {.cell}\n\n```{.r .cell-code}\n   rowSums(A.s)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         7         8         7         4         4         4         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         4         4         6         7         8         5         2 \n   OLIVIA     FLORA \n        2         2 \n```\n:::\n\n```{.r .cell-code}\n   rowSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   EVELYN     LAURA   THERESA    BRENDA CHARLOTTE   FRANCES   ELEANOR     PEARL \n        8         7         8         7         4         4         4         3 \n     RUTH     VERNE     MYRNA KATHERINE    SYLVIA      NORA     HELEN   DOROTHY \n        4         4         4         6         7         8         5         2 \n   OLIVIA     FLORA \n        2         2 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A.s)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    3     3     6     4     8     8    10    14    12     5     4     6     3 \n  8/3 \n    3 \n```\n:::\n\n```{.r .cell-code}\n   colSums(A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 6/27   3/2  4/12  9/26  2/25  5/19  3/15  9/16   4/8  6/10  2/23   4/7 11/21 \n    3     3     6     4     8     8    10    14    12     5     4     6     3 \n  8/3 \n    3 \n```\n:::\n:::\n\n\nAnd now we create our graph ensemble with fixed row *and* column degrees, and test our degree anti-correlation hypothesis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   set.seed(4567)\n   G <- replicate(500, make.swap(A), simplify = FALSE)\n   corrs <- sapply(G, tm.deg.corr)\n```\n:::\n\n\nPlotting the results gives us:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](tm-null_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\nLike before, all of the estimated degree correlations are below zero, and also like before, the observed value does not look as extreme as with the Erdos-Renyi or fixed degree model for either rows or columns separately. \n\nLet's check the p-value at $p < 0.05$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        5% \n-0.3425058 \n```\n:::\n\n```{.r .cell-code}\n   tm.deg.corr(A) < quantile(corrs, probs = 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   5% \nFALSE \n```\n:::\n:::\n\n\nNo longer significant! What's the actual p-value? \n\n\n::: {.cell}\n\n```{.r .cell-code}\n   1 - ecdf(abs(corrs))(abs(tm.deg.corr(A)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.062\n```\n:::\n:::\n\n\nAs suspected, the two-tailed test indicates that the hypothesis of degree anti-correlation is no longer justified in these data even using a criterion of $p < 0.05$. \n\nLooks like our paper won't be published after all :(\n",
    "supporting": [
      "tm-null_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}