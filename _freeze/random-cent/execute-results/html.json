{
  "hash": "81ab6fd0881f38951d5d8d1d749d9c11",
  "result": {
    "markdown": "---\ntitle: \"Random Walk Centralities\"\nexecute: \n  eval: true\n  echo: true\n  output: true\n  warning: false\n  message: false\nformat: \n   html:\n      code-line-numbers: true\n---\n\n\nIn the lecture notes on [random walk concepts](random.qmd) we defined two basic quantities helpful for analyzing networks in terms of dynamic diffusion processes: The **average first passage time** and the **average commute distance**. \n\nBoth of these concepts serve as measures of distances (and its inverse proximity) based on how to two nodes are connected via direct and indirect paths, where the paths are defined by how something (e.g., gossip, disease, a meme) diffuses through the walk structure of the network based on transition probabilities governed by the inverse of the degrees of each node.\n\nIn the lecture on [closeness centrality](closcent.qmd) we saw how one of the fundamental centrality measures in social network analysis is defined according to a distance measure, in that case the **geodesic** or **shortest path distance**. Two nodes are far if the length of the shortest path separating is very long, and are close if it is very short (with the minimum being adjacency or length one).\n\nSince random walk concepts are distance/proximity concepts, we can use them to build analogues of the centrality measures based on the geodesic distance.\n\n## Randon Walk Closeness\n\nThe most obvious extension is to build a measure of closeness based on the random walk concept fo the average first passage time. Two nodes are distant is the average number of steps it takes for something to get from one to the other is big, and they are close if the number of steps is small. So the average first passage time metric is the random-walk analogue to the geodesic distance, but it is based on random walks on *all* paths in the graph regardless of length.\n\nThus, if $m_{ij}$ is the average first passage time between nodes $i$ and $j$ then the **random walk closeness centrality** of node $i$ is given by:\n\n$$\nC^{RCLO}_i = \\left[\\sum_j m_{ij}\\right]^{-1}\n$$ {#eq-rclos}\n\nWhere the denominator of the fraction is just the sum of the rows of the matrix $\\mathbf{M}$\n\nJust like closeness, we can also compute the normalized version of random walk closeness, by taking the average first passage time of each node across all of the other nodes in the graph:\n\n$$\nC^{NRCL}_i = \\frac{N-1}{\\sum_j m_{ij}}\n$$ {#eq-nrclos}\n\nLet's see how this would work in real data. Let's load up our trusty *Pulp Fiction* dataset based on scene co-appearances in the movie:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    library(networkdata)\n    library(igraph)\n    library(stringr) #using stringr to change names from all caps to title case\n    g <- movie_559\n    V(g)$name <- str_to_title(V(g)$name)\n    V(g)$name[which(V(g)$name == \"Esmarelda\")] <- \"Esmeralda\" #fixing misspelled name\n    E(g)$weight <- 1 #setting edge weights to 1.0\n```\n:::\n\n\nFirst, we need the code we used [before](random-cent.qmd) to compute the average first passage time to get our random walk distance matrix $\\mathbf{M}$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    A <- as.matrix(as_adjacency_matrix(g))\n    d <- rowSums(A) #degree vector \n    D <- diag(d) #degree matrix\n    L <- D - A #Laplacian\n    E <- matrix(1, nrow(A), nrow(A))/nrow(A)\n    L.p <- solve(L + E) - E #pseudo-inverse of Laplacian\n    e <- matrix(1, nrow(A), 1) #column vector of all ones\n    l <- diag(L.p) #diagonal vector of Laplacian inverse\n    vol.A <- sum(d) #graph volume \n    M <- vol.A * (e %*% t(l))\n    M <- M - (vol.A * L.p)\n    M <- M + (L.p %*% d) %*% t(e)\n    M <- M - (e %*% (t(d) %*% L.p))\n   round(M[1:10, 1:10], 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Brett Buddy Butch Capt Koons Ed Sullivan English Dave Esmeralda Fabienne\n [1,]   0.0 110.8  13.1       49.1       110.8         53.9     216.1     62.2\n [2,]  35.0   0.0  16.7       44.4       102.0         51.6     219.7     76.6\n [3,]  30.6 110.0   0.0       44.2       110.0         50.6     203.0     69.2\n [4,]  34.5 105.7  12.2        0.0       105.7         52.3     215.2     75.1\n [5,]  35.0 102.0  16.7       44.4         0.0         51.6     219.7     76.6\n [6,]  32.8 106.4  12.0       45.7       106.4          0.0     215.0     74.2\n [7,]  31.6 111.0   1.0       45.2       111.0         51.6       0.0     70.2\n [8,]  21.6 111.8  11.1       49.1       111.8         54.6     214.1      0.0\n [9,]  33.2 109.2  18.2       49.7       109.2         55.8     221.2     73.4\n[10,]  31.1 111.2   7.8       47.6       111.2         50.9     210.8     72.2\n      Fourth Man Gawker #2\n [1,]      106.1      83.0\n [2,]      106.3      87.3\n [3,]      108.5      77.2\n [4,]      108.0      84.9\n [5,]      106.3      87.3\n [6,]      107.6      81.7\n [7,]      109.5      78.2\n [8,]      105.7      83.5\n [9,]        0.0      88.4\n[10,]      109.4       0.0\n```\n:::\n:::\n\n\nAnd here are the first ten rows and columns of the $\\mathbf{M}$ mmatrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    rownames(M) <- colnames(M)\n    round(M, 1)[1:10, 1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Brett Buddy Butch Capt Koons Ed Sullivan English Dave Esmeralda\nBrett          0.0 110.8  13.1       49.1       110.8         53.9     216.1\nBuddy         35.0   0.0  16.7       44.4       102.0         51.6     219.7\nButch         30.6 110.0   0.0       44.2       110.0         50.6     203.0\nCapt Koons    34.5 105.7  12.2        0.0       105.7         52.3     215.2\nEd Sullivan   35.0 102.0  16.7       44.4         0.0         51.6     219.7\nEnglish Dave  32.8 106.4  12.0       45.7       106.4          0.0     215.0\nEsmeralda     31.6 111.0   1.0       45.2       111.0         51.6       0.0\nFabienne      21.6 111.8  11.1       49.1       111.8         54.6     214.1\nFourth Man    33.2 109.2  18.2       49.7       109.2         55.8     221.2\nGawker #2     31.1 111.2   7.8       47.6       111.2         50.9     210.8\n             Fabienne Fourth Man Gawker #2\nBrett            62.2      106.1      83.0\nBuddy            76.6      106.3      87.3\nButch            69.2      108.5      77.2\nCapt Koons       75.1      108.0      84.9\nEd Sullivan      76.6      106.3      87.3\nEnglish Dave     74.2      107.6      81.7\nEsmeralda        70.2      109.5      78.2\nFabienne          0.0      105.7      83.5\nFourth Man       73.4        0.0      88.4\nGawker #2        72.2      109.4       0.0\n```\n:::\n:::\n\n\nNow to compute random walk closeness according to @eq-rclos:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   rw.clos <- rowSums(M)^-1\n   sort(rw.clos, decreasing = TRUE)[1:10] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       The Gimp             Zed Sportscaster #2         Maynard Sportscaster #1 \n   0.0003172878    0.0003172878    0.0003158847    0.0003049048    0.0003001459 \n      Esmeralda       Gawker #2      Pedestrian           Buddy     Ed Sullivan \n   0.0002890414    0.0002776414    0.0002776414    0.0002773396    0.0002773396 \n```\n:::\n:::\n\n\nAnd the normalized version:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   nrw.clos <- (vcount(g) - 1)/rowSums(M)\n   sort(nrw.clos, decreasing = TRUE)[1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       The Gimp             Zed Sportscaster #2         Maynard Sportscaster #1 \n     0.01173965      0.01173965      0.01168773      0.01128148      0.01110540 \n      Esmeralda       Gawker #2      Pedestrian           Buddy     Ed Sullivan \n     0.01069453      0.01027273      0.01027273      0.01026157      0.01026157 \n```\n:::\n:::\n\n\nNote that in contrast to the measures based on shortest paths, in which the top characters also have the top closeness, the random walk version selects more obscure characters as the most central (e.g., The Gimp and Zed).\n\nNote that because the average first passage time is an asymmetric measure, we have a choice as to whether to compute it based on the \"out\" or the \"in\" distances. When we use the row sums of the $\\mathbf{M}$ matrix we count a node as close if the average first passage time between them and the other nodes in the graph is small. \n\nBut we can also say that a node is close to others if the average first passage time between the others and that node is small. In that case we would want to use the *column sums* of the $\\mathbf{M}$ matrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   nrw.clos <- (vcount(g) - 1)/colSums(M)\n   sort(nrw.clos, decreasing = TRUE)[1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Vincent       Butch       Jules         Mia   Marsellus       Brett \n 0.10885425  0.06704354  0.06392210  0.04047785  0.04008249  0.02937037 \n     Marvin       Roger Honey Bunny     Pumpkin \n 0.02620981  0.02620981  0.02388114  0.02388114 \n```\n:::\n:::\n\n\nNote that using this measure gives us more interpretable results, with the most important characters in the story being in the top ten.\n\n## Current Flow Closeness\n\nWhat if we were to use the average commute time as our distance measure instead? This makes sense, because just like the average first passage time, two nodes are far if the average commute time between them is big, and close if it is small. \n\nIf we do that, we end up with a closeness centrality measure called **Current Flow Closeness** which is a weird name due to the fact that it was developed in the study of electrical circuit networks!\n\nSo if $n_{ij}$ is the average commute time distance between nodes $i$ and $j$ then the current flow closeness of $i$ is given by:\n\n$$\nC^{CFCL}_i = \\left[\\sum_j n_{ij}\\right]^{-1}\n$$ {#eq-cfclos}\n\nAnd the normalized version:\n\n$$\nC^{NCFC}_i = \\frac{N-1}{\\sum_j n_{ij}}\n$$ {#eq-nrclos}\n\n\nRemember that once we have $\\mathbf{M}$, the $\\mathbf{N}$ matrix of average commute time distances is just:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   N <- M + t(M)\n```\n:::\n\n\nAnd here are the first ten rows and columns of the $\\mathbf{N}$ mmatrix:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   round(N, 1)[1:10, 1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Brett Buddy Butch Capt Koons Ed Sullivan English Dave Esmeralda\nBrett          0.0 145.8  43.6       83.6       145.8         86.7     247.6\nBuddy        145.8   0.0 126.8      150.1       204.0        158.0     330.8\nButch         43.6 126.8   0.0       56.3       126.8         62.6     204.0\nCapt Koons    83.6 150.1  56.3        0.0       150.1         98.0     260.3\nEd Sullivan  145.8 204.0 126.8      150.1         0.0        158.0     330.8\nEnglish Dave  86.7 158.0  62.6       98.0       158.0          0.0     266.6\nEsmeralda    247.6 330.8 204.0      260.3       330.8        266.6       0.0\nFabienne      83.7 188.3  80.3      124.2       188.3        128.8     284.3\nFourth Man   139.3 215.4 126.7      157.7       215.4        163.4     330.7\nGawker #2    114.1 198.5  85.0      132.5       198.5        132.5     289.0\n             Fabienne Fourth Man Gawker #2\nBrett            83.7      139.3     114.1\nBuddy           188.3      215.4     198.5\nButch            80.3      126.7      85.0\nCapt Koons      124.2      157.7     132.5\nEd Sullivan     188.3      215.4     198.5\nEnglish Dave    128.8      163.4     132.5\nEsmeralda       284.3      330.7     289.0\nFabienne          0.0      179.1     155.7\nFourth Man      179.1        0.0     197.8\nGawker #2       155.7      197.8       0.0\n```\n:::\n:::\n\n\nAnd now to compute the current flow closeness:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   cf.clos <- rowSums(N/sum(d))^-1\n   sort(cf.clos, decreasing = TRUE)[1:10] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Vincent       Butch       Jules         Mia   Marsellus       Brett \n 0.05076202  0.04883195  0.04788957  0.04459401  0.04443553  0.04139034 \n     Marvin       Roger Honey Bunny     Pumpkin \n 0.04015006  0.04015006  0.03897407  0.03897407 \n```\n:::\n:::\n\n\nNote that we divided the entries in the average commute time matrix $\\mathbf{N}$ by the volume of the graph $\\sum_i d_i$ (the sum of degrees) to transform them into **resistance distances** [@fouss_etal16, p. 78], which does not make a difference for the rankings because it is just dividing by a constant.\n\nAnd the normalized version:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n   ncf.clos <- (vcount(g)-1)/rowSums(N/sum(d))\n   sort(ncf.clos, decreasing = TRUE)[1:10] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Vincent       Butch       Jules         Mia   Marsellus       Brett \n   1.878195    1.806782    1.771914    1.649978    1.644115    1.531442 \n     Marvin       Roger Honey Bunny     Pumpkin \n   1.485552    1.485552    1.442041    1.442041 \n```\n:::\n:::\n\n\nWe can see that in contrast to the random walk closeness based on out-distances, but like the random walk closeness based on in-distances, the current flow closeness gives results that are closer to those obtained using the geodesic distance version of closeness with the most important characters in the story being in the top ten. \n\n## Random Walk Betweenness\n\nWe can extend a similar \"random walk\" reasoning to the concept of [betweenness centrality](betcent.qmd). Recall that the standard computation of betweenness centrality only counts the number *shortest paths* that a given node is an intermediary on. We can extend the same reasoning beyond shortest paths to consider all paths of any length.\n\nConsider a random walk process on a social network of the sort we [talked about before](random.qmd). In this version we select a \"seed\" or \"source\" node $i$ and a destination (also called \"sink) node $j$. We start a diffusion process on $i$ and stop it when it reaches $j$. The node-to-node transition are governed by the probabilities stored in the matrix $\\mathbf{P}$.\n\nIf we replay this process many times, each time selecting a random source and a random destination node in the network (such that all pairs of nodes get to play each role) then we *could* count the number of times the thing diffusing through the network when *through* some third node $k$. A node has a high **random walk betweenness centrality** if it is likely to be an intermediary on most random walk diffusion processes that start and end with some other pair of nodes $i$ and $j$. \n\n### Computing Random Walk Betweeness\n\nHow do we calculate random walk betweenness? Turns out the information we seek is stored in the **pseudo-inverse of the Laplacian** matrix ($\\mathbf{L}^+$), which you recall from our [previous discussion](random.qmd) is defined as:\n\n$$\n\\mathbf{L}^+ = \\left(\\mathbf{L} -  \\frac{\\mathbf{E}}{N}\\right) ^{-1}- \\frac{\\mathbf{E}}{N}\n$$ {#eq-ilap}\n\nWhere $\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$, $\\mathbf{D}$ is the matrix containing the degrees of each node in the diagonal, $\\mathbf{E}$ is the all ones matrix of the same dimension as $\\mathbf{A}$, and $N$ is the number of nodes in the network. Note that we already computed this matrix when calculating random walk closeness earlier for the *Pulp Fiction* network (`L.p`).\n\nAs @fouss_etal16 [p. 161] note, if we wanted to know the amount of \"flow\" ($\\phi$) that goes through a node $k$ during a random walk process involving a seed node $i$ and destination node $l$ all we need to do is compute:\n\n$$\n\\phi_k = \\frac{1}{2}\\sum_{j \\in N(k)}^{N} a_{jk}|l_{ij}^+ - l_{jl}^+ - l_{ik}^+ + l_{kl}^+|\n$$ {#eq-flow1}\n\nWhere the summation goes over all of $k$'s neighbors $j$. What this formula tells us is that the amount of flow that $k$ intermediates when a random walk process starts at $i$ and ends with $l$ is the sum of the amount of flow that would come through each edge $e_{jk}$ in the graph, connecting $k$ to one of their neighbors $j$.\n\nLet's write a function to test this out in the *Pulp Fiction* network:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    flow.k <- function(a, b, c, w) {\n        z <- as.matrix(as_adjacency_matrix(w))\n        i <- which(V(w)$name == a)\n        l <- which(V(w)$name == b)\n        k <- which(V(w)$name == c)\n        f <- 0\n        for (j in 1:vcount(w)) {\n            if (i !=k & l != k) {\n                f <- f + (z[j,k] * abs(L.p[i,j] - L.p[j,l] - L.p[i,k] + L.p[k,l]))\n                }\n            }\n        f <- f/2\n        return(f)\n        }\n```\n:::\n\n\nThe `flow.k` function takes the seed node `a`, the destination node `b`, the intermediary node `c` and the graph `w` as arguments, and returns the total amount of flow that would go from each of $k$'s neighbors $j$ as output according to @eq-flow1.\n\nFor instance, if we wanted to find the amount of flow that would go through Vincent if we started a random walk process with Mia and ended it with Pumpkin an infinite number of times, we would just type:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    round(flow.k(\"Mia\", \"Pumpkin\", \"Vincent\", g), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.711\n```\n:::\n:::\n\n\nAnd if we wanted to change to the intermediary node to Brett:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    round(flow.k(\"Mia\", \"Pumpkin\", \"Brett\", g), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.048\n```\n:::\n:::\n\n\nIndicating that Vincent would intermediate much more of the flow between Mia and Pumpkin than would Brett. \n\nNow, the overall random walk betweenness centrality of any node is just their average flow score across each pair of nodes in the graph. The following wrapper around `flow.k` figures that out:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    flow.bet <- function(c, w) {\n        b <- 0\n        n <- vcount(w)\n        for (i in V(w)$name) {\n            for (j in V(w)$name) {\n                b <- b + flow.k(i, j, c, w) #summing flows\n            }\n        }\n        b <- b * ((n - 1) * (n- 2))^-1 #averaging across pairs\n        return(b)\n    }\n```\n:::\n\n\nWe can now find Vincent's random walk betweenness:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    round(flow.bet(\"Vincent\", g), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.498\n```\n:::\n:::\n\n\nWhich is higher than Brett's\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    round(flow.bet(\"Brett\", g), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.077\n```\n:::\n:::\n\n\n@fouss_etal16 [p. 162] show that we can use some matrix tricks to compute these quantities more efficiently. First, they note that the total flow going through a particular edge $e_{jk}$ in the graph for every source/destination pair of nodes can be computed as follows. \n\nFirst, we compute the matrix $\\mathbf{N}_{jk}$:\n\n$$\n\\mathbf{N}_{jk} = (\\mathbf{l}^+_j  - \\mathbf{l}^+_k)\\mathbf{e^T} - \\mathbf{e}(\\mathbf{l}^+_j  - \\mathbf{l}^+_k)^T\n$$\n\nWhere $\\mathbf{l}^+_j$ is the $j^{th}$ column of $\\mathbf{L}^+$.\n\nOnce we have $\\mathbf{N}_{jk}$, the total random walk flow going through edge $e_{jk}$ is given by:\n\n$$\n\\phi_{jk} = (\\mathbf{e} - \\mathbf{e}_k)^T |\\mathbf{N}_{jk}| (\\mathbf{e} - \\mathbf{e}_k)\n$$\n\nThe random walk betweenness of $k$ is then the sum of $\\phi_{jk}$ across each neighbor $j \\in N(k)$.\n\nHere's a function that packages those tricks to compute the random walk betweenness of each node in the graph, based on @fouss_etal16 [algorithm 4.5]:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    cur.flow.bet <- function(w) {\n        n <- vcount(w)\n        b <- rep(0, n)\n        for (k in 1:n) {\n            l.k <- L.p[, k]\n            for (j in as.vector(neighbors(w, k))) {\n                l.j <- L.p[, j]\n                Njk <- ((l.j - l.k) %*% t(e)) - (e %*% t(l.j - l.k))\n                e.k <- matrix(0, n, 1)\n                e.k[k] <- 1\n                b[k] <- b[k] + (t(e - e.k) %*% abs(Njk) %*% (e - e.k))\n            }\n        }\n    b <- b * (2 * ((n - 1) * (n- 2)))^-1 #averaging across pairs\n    names(b) <- V(w)$name\n    return(b)\n    }\n```\n:::\n\n\nAnd now for the big reveal:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n    cf.bet <- cur.flow.bet(g)\n    round(sort(cf.bet, decreasing = TRUE), 3)[1:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Vincent       Butch       Jules         Mia   Marsellus     Pumpkin \n      0.498       0.454       0.309       0.187       0.147       0.115 \nHoney Bunny     Maynard       Brett      Marvin \n      0.115       0.106       0.077       0.060 \n```\n:::\n:::\n\n\nWhich gives us the same answer as we obtained earlier for Vincent (the top node) while also showing the other top random walk betweenness centrality nodes in the network. These nodes, are not surprisingly, also some of the most central characters in the story. ",
    "supporting": [
      "random-cent_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}